{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d12af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:37:26.777770Z",
     "iopub.status.busy": "2024-11-04T10:37:26.776687Z",
     "iopub.status.idle": "2024-11-04T10:37:30.607848Z",
     "shell.execute_reply": "2024-11-04T10:37:30.606290Z"
    },
    "papermill": {
     "duration": 3.841986,
     "end_time": "2024-11-04T10:37:30.610605",
     "exception": false,
     "start_time": "2024-11-04T10:37:26.768619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from catboost.utils import get_gpu_device_count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f975932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:37:30.624333Z",
     "iopub.status.busy": "2024-11-04T10:37:30.622851Z",
     "iopub.status.idle": "2024-11-04T10:37:30.636384Z",
     "shell.execute_reply": "2024-11-04T10:37:30.635159Z"
    },
    "papermill": {
     "duration": 0.022595,
     "end_time": "2024-11-04T10:37:30.638862",
     "exception": false,
     "start_time": "2024-11-04T10:37:30.616267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 35 (CUDA driver version is insufficient for CUDA runtime version) ignored while obtaining device count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CPU'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_gpu_available = get_gpu_device_count()\n",
    "device = 'GPU' if is_gpu_available else 'CPU'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436f20d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:37:30.651446Z",
     "iopub.status.busy": "2024-11-04T10:37:30.651008Z",
     "iopub.status.idle": "2024-11-04T10:37:30.656187Z",
     "shell.execute_reply": "2024-11-04T10:37:30.654850Z"
    },
    "papermill": {
     "duration": 0.014053,
     "end_time": "2024-11-04T10:37:30.658425",
     "exception": false,
     "start_time": "2024-11-04T10:37:30.644372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = r'/data/Кейс-3. Отток юридических лиц из расчетно-кассового обслуживания/train'\n",
    "TEST_PATH = r'/data/Кейс-3. Отток юридических лиц из расчетно-кассового обслуживания/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066e4ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:37:30.670630Z",
     "iopub.status.busy": "2024-11-04T10:37:30.670239Z",
     "iopub.status.idle": "2024-11-04T10:38:02.378983Z",
     "shell.execute_reply": "2024-11-04T10:38:02.377827Z"
    },
    "papermill": {
     "duration": 31.717941,
     "end_time": "2024-11-04T10:38:02.381747",
     "exception": false,
     "start_time": "2024-11-04T10:37:30.663806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    filenames_train = glob.glob(path + '/*.csv')\n",
    "    data_files_train = []\n",
    "    \n",
    "    for filename in filenames_train:\n",
    "        data_files_train.append(pd.read_csv(filename))\n",
    "\n",
    "    return pd.concat(data_files_train, ignore_index=True)\n",
    "\n",
    "train_df = get_data(TRAIN_PATH)\n",
    "test_df = get_data(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de00afcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:38:02.394189Z",
     "iopub.status.busy": "2024-11-04T10:38:02.393736Z",
     "iopub.status.idle": "2024-11-04T10:38:02.409512Z",
     "shell.execute_reply": "2024-11-04T10:38:02.408382Z"
    },
    "papermill": {
     "duration": 0.025295,
     "end_time": "2024-11-04T10:38:02.412405",
     "exception": false,
     "start_time": "2024-11-04T10:38:02.387110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = test_df['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48bf527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:38:02.425401Z",
     "iopub.status.busy": "2024-11-04T10:38:02.424839Z",
     "iopub.status.idle": "2024-11-04T10:38:02.434427Z",
     "shell.execute_reply": "2024-11-04T10:38:02.433152Z"
    },
    "papermill": {
     "duration": 0.019047,
     "end_time": "2024-11-04T10:38:02.437252",
     "exception": false,
     "start_time": "2024-11-04T10:38:02.418205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = [\n",
    "       'feature_168', 'feature_87', 'feature_72', 'feature_124', 'feature_141',\n",
    "       'feature_29', 'feature_55', 'feature_142', 'feature_78', 'feature_183',\n",
    "       'feature_84', 'feature_146', 'feature_134', 'feature_26', 'feature_12',\n",
    "       'feature_127', 'feature_59', 'feature_100', 'feature_96', 'feature_112',\n",
    "       'feature_169', 'feature_16', 'feature_76', 'feature_81', 'feature_79',\n",
    "       'feature_22', 'feature_152', 'feature_43', 'feature_20', 'feature_18',\n",
    "       'feature_44', 'id', 'feature_177', 'feature_50', 'feature_6',\n",
    "       'feature_66', 'feature_9', 'feature_46', 'feature_103', 'feature_75',\n",
    "       'feature_8', 'feature_36', 'feature_41', 'feature_184', 'feature_62',\n",
    "       'feature_95', 'feature_133', 'feature_28', 'feature_108', 'feature_128',\n",
    "       'feature_117', 'feature_161', 'feature_157', 'feature_107', 'feature_147'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5f08d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:38:02.450023Z",
     "iopub.status.busy": "2024-11-04T10:38:02.449598Z",
     "iopub.status.idle": "2024-11-04T10:38:02.549467Z",
     "shell.execute_reply": "2024-11-04T10:38:02.548245Z"
    },
    "papermill": {
     "duration": 0.109311,
     "end_time": "2024-11-04T10:38:02.552074",
     "exception": false,
     "start_time": "2024-11-04T10:38:02.442763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[f + ['target']]\n",
    "test_df = test_df[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d366952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:38:02.566959Z",
     "iopub.status.busy": "2024-11-04T10:38:02.565911Z",
     "iopub.status.idle": "2024-11-04T10:38:02.652619Z",
     "shell.execute_reply": "2024-11-04T10:38:02.651338Z"
    },
    "papermill": {
     "duration": 0.096972,
     "end_time": "2024-11-04T10:38:02.656019",
     "exception": false,
     "start_time": "2024-11-04T10:38:02.559047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "feature_operations = {\n",
    "    'atan_feature_112': ('feature_112', np.arctan),\n",
    "    'log_feature_26': ('feature_26', np.log1p),\n",
    "    'sin_feature_26': ('feature_26', np.sin),\n",
    "    'tan_feature_26': ('feature_26', np.tan)\n",
    "}\n",
    "\n",
    "for new_feature, (base_feature, operation) in feature_operations.items():\n",
    "    train_df[new_feature] = operation(train_df[base_feature])\n",
    "    test_df[new_feature] = operation(test_df[base_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6deb53db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:38:02.669166Z",
     "iopub.status.busy": "2024-11-04T10:38:02.668224Z",
     "iopub.status.idle": "2024-11-04T10:40:38.728347Z",
     "shell.execute_reply": "2024-11-04T10:40:38.726909Z"
    },
    "papermill": {
     "duration": 156.069569,
     "end_time": "2024-11-04T10:40:38.731139",
     "exception": false,
     "start_time": "2024-11-04T10:38:02.661570",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightautoml\r\n",
      "  Downloading lightautoml-0.3.8.1-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting autowoe>=1.2 (from lightautoml)\r\n",
      "  Downloading AutoWoE-1.3.2-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.2.7)\r\n",
      "Collecting cmaes (from lightautoml)\r\n",
      "  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml) (0.57)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (3.1.4)\r\n",
      "Collecting joblib<1.3.0 (from lightautoml)\r\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting json2html (from lightautoml)\r\n",
      "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting lightgbm<=3.2.1,>=2.3 (from lightautoml)\r\n",
      "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml) (3.3)\r\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.26.4)\r\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml) (4.0.0)\r\n",
      "Collecting pandas<2.0.0 (from lightautoml)\r\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting poetry-core<2.0.0,>=1.0.0 (from lightautoml)\r\n",
      "  Downloading poetry_core-1.9.1-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml) (6.0.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.2.2)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml) (0.12.2)\r\n",
      "Collecting statsmodels<=0.14.0 (from lightautoml)\r\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\r\n",
      "Collecting torch<=2.0.0,>=1.9.0 (from lightautoml)\r\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml) (4.66.4)\r\n",
      "Collecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.2->lightautoml)\r\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (3.7.5)\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (8.3.3)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (2024.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (1.14.1)\r\n",
      "Collecting sphinx (from autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (0.2.4)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (0.20.3)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (1.16.0)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.43.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml) (2.9.0.post0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml) (3.5.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml) (21.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (1.12)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.0.0 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.0,>=1.9.0->lightautoml) (70.0.0)\r\n",
      "Collecting cmake (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading cmake-3.30.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\r\n",
      "Collecting lit (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml) (2.1.5)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (1.13.3)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (6.8.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (2.0.30)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.1.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (3.0.3)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml) (8.3.0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.5.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.1)\r\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-jsmath>=1.0.1 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: Pygments>=2.17 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.18.0)\r\n",
      "Collecting docutils<0.22,>=0.20 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\r\n",
      "Requirement already satisfied: babel>=2.13 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.15.0)\r\n",
      "Collecting alabaster>=0.7.14 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting imagesize>=1.3 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: requests>=2.30.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.32.3)\r\n",
      "Collecting packaging>=21.3 (from statsmodels<=0.14.0->lightautoml)\r\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml) (1.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (2024.8.30)\r\n",
      "Downloading lightautoml-0.3.8.1-py3-none-any.whl (416 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.4/416.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading AutoWoE-1.3.2-py3-none-any.whl (215 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.7/215.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading poetry_core-1.9.1-py3-none-any.whl (309 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cmaes-0.11.1-py3-none-any.whl (35 kB)\r\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\r\n",
      "Downloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading alabaster-1.0.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\r\n",
      "Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\r\n",
      "Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cmake-3.30.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: json2html\r\n",
      "  Building wheel for json2html (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7593 sha256=9ef41434f46e4b54c90c9a56032c92eb035b17491ea2bc0e0f5fcd288c89dcb9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/d8/b3/6f83a04ab0ec00e691de794d108286bb0f8bcdf4ade19afb57\r\n",
      "Successfully built json2html\r\n",
      "Installing collected packages: StrEnum, lit, json2html, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, poetry-core, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, joblib, imagesize, docutils, cmake, cmaes, alabaster, sphinx, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, statsmodels, lightgbm, autowoe, triton, torch, lightautoml\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.4.2\r\n",
      "    Uninstalling joblib-1.4.2:\r\n",
      "      Successfully uninstalled joblib-1.4.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "  Attempting uninstall: statsmodels\r\n",
      "    Found existing installation: statsmodels 0.14.2\r\n",
      "    Uninstalling statsmodels-0.14.2:\r\n",
      "      Successfully uninstalled statsmodels-0.14.2\r\n",
      "  Attempting uninstall: lightgbm\r\n",
      "    Found existing installation: lightgbm 4.2.0\r\n",
      "    Uninstalling lightgbm-4.2.0:\r\n",
      "      Successfully uninstalled lightgbm-4.2.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.4.0+cpu\r\n",
      "    Uninstalling torch-2.4.0+cpu:\r\n",
      "      Successfully uninstalled torch-2.4.0+cpu\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0 which is incompatible.\r\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "torchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.0.0 which is incompatible.\r\n",
      "torchvision 0.19.0+cpu requires torch==2.4.0, but you have torch 2.0.0 which is incompatible.\r\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-1.0.0 autowoe-1.3.2 cmaes-0.11.1 cmake-3.30.5 docutils-0.21.2 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8.1 lightgbm-3.2.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 packaging-24.1 pandas-1.5.3 poetry-core-1.9.1 sphinx-8.1.3 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 statsmodels-0.14.0 torch-2.0.0 triton-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f38633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:40:38.850711Z",
     "iopub.status.busy": "2024-11-04T10:40:38.850237Z",
     "iopub.status.idle": "2024-11-04T10:41:11.991425Z",
     "shell.execute_reply": "2024-11-04T10:41:11.990427Z"
    },
    "papermill": {
     "duration": 33.204796,
     "end_time": "2024-11-04T10:41:11.994067",
     "exception": false,
     "start_time": "2024-11-04T10:40:38.789271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70560816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:41:12.115334Z",
     "iopub.status.busy": "2024-11-04T10:41:12.114576Z",
     "iopub.status.idle": "2024-11-04T10:41:12.120327Z",
     "shell.execute_reply": "2024-11-04T10:41:12.119246Z"
    },
    "papermill": {
     "duration": 0.068483,
     "end_time": "2024-11-04T10:41:12.122620",
     "exception": false,
     "start_time": "2024-11-04T10:41:12.054137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "N_FOLDS = 7\n",
    "RANDOM_STATE = 52\n",
    "TIMEOUT = 36000\n",
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06127a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:41:12.246916Z",
     "iopub.status.busy": "2024-11-04T10:41:12.246504Z",
     "iopub.status.idle": "2024-11-04T10:41:12.254400Z",
     "shell.execute_reply": "2024-11-04T10:41:12.252725Z"
    },
    "papermill": {
     "duration": 0.073835,
     "end_time": "2024-11-04T10:41:12.257361",
     "exception": false,
     "start_time": "2024-11-04T10:41:12.183526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3afb163e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:41:12.382593Z",
     "iopub.status.busy": "2024-11-04T10:41:12.381880Z",
     "iopub.status.idle": "2024-11-04T10:41:12.389300Z",
     "shell.execute_reply": "2024-11-04T10:41:12.388313Z"
    },
    "papermill": {
     "duration": 0.072243,
     "end_time": "2024-11-04T10:41:12.391710",
     "exception": false,
     "start_time": "2024-11-04T10:41:12.319467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c082accd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:41:12.518377Z",
     "iopub.status.busy": "2024-11-04T10:41:12.517486Z",
     "iopub.status.idle": "2024-11-04T10:41:12.571525Z",
     "shell.execute_reply": "2024-11-04T10:41:12.570271Z"
    },
    "papermill": {
     "duration": 0.119005,
     "end_time": "2024-11-04T10:41:12.574000",
     "exception": false,
     "start_time": "2024-11-04T10:41:12.454995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# automl = TabularAutoML(\n",
    "#     task=Task('binary', loss='logloss', metric='auc'), \n",
    "#     reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE, 'advanced_roles': False},\n",
    "#     timeout=TIMEOUT,\n",
    "#     cpu_limit=N_THREADS,\n",
    "#     debug=True,\n",
    "#     general_params={\n",
    "#         \"use_algos\": [\n",
    "#             [\n",
    "#                 'lgb', \n",
    "#                 'lgb_tuned', \n",
    "#                 'xgb', \n",
    "#                 'xgb_tuned', \n",
    "#                 'fttransformer_tuned', \n",
    "#                 'autoint_tuned'\n",
    "#             ]\n",
    "#         ]\n",
    "#     },\n",
    "#     nn_params={\n",
    "#         \"0\": {\n",
    "#             \"bs\": 1024,\n",
    "#             'lr': 1e-3,\n",
    "#             \"freeze_defaults\": True,\n",
    "#             \"cont_embedder\": 'plr',\n",
    "#             \"n_epochs\": 15,\n",
    "#             'path_to_save': '/kaggle/working/fttransformer',\n",
    "#         },\n",
    "#         '1': {\n",
    "#             \"bs\": 1024,\n",
    "#             'lr': 1e-3,\n",
    "#             \"freeze_defaults\": True,\n",
    "#             \"n_epochs\": 15,\n",
    "#             'path_to_save': '/kaggle/working/autoint',\n",
    "#         }\n",
    "#     },\n",
    "#     tuning_params={'max_tuning_time': 3600, 'max_tuning_iter': 101, 'fit_on_holdout': True},\n",
    "#     selection_params={'mode': 0},\n",
    "#     gpu_ids='0'\n",
    "# )\n",
    "\n",
    "automl = TabularAutoML(\n",
    "    task=Task('binary', loss='logloss', metric='auc'), \n",
    "    reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE, 'advanced_roles': False},\n",
    "    tuning_params={'max_tuning_time': 3600, 'max_tuning_iter': 200, 'fit_on_holdout': True},\n",
    "    timeout=TIMEOUT,\n",
    "    cpu_limit=N_THREADS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a01b2bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T10:41:12.700965Z",
     "iopub.status.busy": "2024-11-04T10:41:12.700571Z",
     "iopub.status.idle": "2024-11-04T13:20:49.831536Z",
     "shell.execute_reply": "2024-11-04T13:20:49.830050Z"
    },
    "papermill": {
     "duration": 9577.196321,
     "end_time": "2024-11-04T13:20:49.834597",
     "exception": false,
     "start_time": "2024-11-04T10:41:12.638276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:41:12] Stdout logging level is INFO3.\n",
      "[10:41:12] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[10:41:12] Task: binary\n",
      "\n",
      "[10:41:12] Start automl preset with listed constraints:\n",
      "[10:41:12] - time: 36000.00 seconds\n",
      "[10:41:12] - CPU: 4 cores\n",
      "[10:41:12] - memory: 16 GB\n",
      "\n",
      "[10:41:12] \u001b[1mTrain data shape: (413194, 60)\u001b[0m\n",
      "\n",
      "[10:41:13] Layer \u001b[1m1\u001b[0m train process start. Time left 35998.76 secs\n",
      "[10:41:15] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[10:41:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:15] Linear model: C = 1e-05 score = 0.7797954896547298\n",
      "[10:41:16] Linear model: C = 5e-05 score = 0.7826892712398302\n",
      "[10:41:16] Linear model: C = 0.0001 score = 0.7834345714976454\n",
      "[10:41:16] Linear model: C = 0.0005 score = 0.7840509723841159\n",
      "[10:41:16] Linear model: C = 0.001 score = 0.7840509723841159\n",
      "[10:41:16] Linear model: C = 0.005 score = 0.7840507579307839\n",
      "[10:41:16] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:17] Linear model: C = 1e-05 score = 0.7866292156047449\n",
      "[10:41:17] Linear model: C = 5e-05 score = 0.7902107696954355\n",
      "[10:41:17] Linear model: C = 0.0001 score = 0.791077897532193\n",
      "[10:41:18] Linear model: C = 0.0005 score = 0.7920079583786493\n",
      "[10:41:18] Linear model: C = 0.001 score = 0.7920079583786493\n",
      "[10:41:18] Linear model: C = 0.005 score = 0.7920079609624243\n",
      "[10:41:18] Linear model: C = 0.01 score = 0.7920080203892513\n",
      "[10:41:18] Linear model: C = 0.05 score = 0.7920086766681224\n",
      "[10:41:18] Linear model: C = 0.1 score = 0.792011363794209\n",
      "[10:41:18] Linear model: C = 0.5 score = 0.792011363794209\n",
      "[10:41:18] Linear model: C = 1 score = 0.792011363794209\n",
      "[10:41:18] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:19] Linear model: C = 1e-05 score = 0.7837593236040629\n",
      "[10:41:19] Linear model: C = 5e-05 score = 0.7869013801368963\n",
      "[10:41:19] Linear model: C = 0.0001 score = 0.7877147628681508\n",
      "[10:41:20] Linear model: C = 0.0005 score = 0.7885025636423076\n",
      "[10:41:20] Linear model: C = 0.001 score = 0.7885025636423076\n",
      "[10:41:20] Linear model: C = 0.005 score = 0.7885021244005435\n",
      "[10:41:20] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:21] Linear model: C = 1e-05 score = 0.7814700730427016\n",
      "[10:41:21] Linear model: C = 5e-05 score = 0.7850342486621831\n",
      "[10:41:21] Linear model: C = 0.0001 score = 0.7858516956716434\n",
      "[10:41:21] Linear model: C = 0.0005 score = 0.7866538880730132\n",
      "[10:41:21] Linear model: C = 0.001 score = 0.7866538880730132\n",
      "[10:41:22] Linear model: C = 0.005 score = 0.786653482420325\n",
      "[10:41:22] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:22] Linear model: C = 1e-05 score = 0.7814835112569086\n",
      "[10:41:22] Linear model: C = 5e-05 score = 0.7846098765236624\n",
      "[10:41:23] Linear model: C = 0.0001 score = 0.7853395940339517\n",
      "[10:41:23] Linear model: C = 0.0005 score = 0.7862532711626061\n",
      "[10:41:23] Linear model: C = 0.001 score = 0.7862532711626061\n",
      "[10:41:23] Linear model: C = 0.005 score = 0.7862530334552986\n",
      "[10:41:23] ===== Start working with \u001b[1mfold 5\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:23] Linear model: C = 1e-05 score = 0.7821783675190486\n",
      "[10:41:24] Linear model: C = 5e-05 score = 0.7855353861923693\n",
      "[10:41:24] Linear model: C = 0.0001 score = 0.78638440258106\n",
      "[10:41:24] Linear model: C = 0.0005 score = 0.7872343597339047\n",
      "[10:41:24] Linear model: C = 0.001 score = 0.7872336722524073\n",
      "[10:41:24] Linear model: C = 0.005 score = 0.7872333931245814\n",
      "[10:41:25] ===== Start working with \u001b[1mfold 6\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
      "[10:41:25] Linear model: C = 1e-05 score = 0.7755719055196555\n",
      "[10:41:25] Linear model: C = 5e-05 score = 0.7792558268140444\n",
      "[10:41:25] Linear model: C = 0.0001 score = 0.7802678150853827\n",
      "[10:41:26] Linear model: C = 0.0005 score = 0.7812587602200586\n",
      "[10:41:26] Linear model: C = 0.001 score = 0.7812587395439232\n",
      "[10:41:26] Linear model: C = 0.005 score = 0.7812575997719671\n",
      "[10:41:26] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.786562567035478\u001b[0m\n",
      "[10:41:26] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[10:41:26] Time left 35986.29 secs\n",
      "\n",
      "[10:41:28] Training until validation scores don't improve for 100 rounds\n",
      "[10:42:04] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:42:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[10:42:04] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:42:06] Training until validation scores don't improve for 100 rounds\n",
      "[10:42:42] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:42:44] Training until validation scores don't improve for 100 rounds\n",
      "[10:43:11] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:43:13] Training until validation scores don't improve for 100 rounds\n",
      "[10:43:44] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:43:46] Training until validation scores don't improve for 100 rounds\n",
      "[10:44:13] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:44:15] Training until validation scores don't improve for 100 rounds\n",
      "[10:44:37] ===== Start working with \u001b[1mfold 5\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:44:39] Training until validation scores don't improve for 100 rounds\n",
      "[10:45:07] ===== Start working with \u001b[1mfold 6\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
      "[10:45:08] Training until validation scores don't improve for 100 rounds\n",
      "[10:45:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8082485025557037\u001b[0m\n",
      "[10:45:37] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:45:37] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 3600.00 secs\n",
      "[10:45:39] Training until validation scores don't improve for 100 rounds\n",
      "[10:46:01] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.805572162626359 in 0:00:23.912618\n",
      "[10:46:03] Training until validation scores don't improve for 100 rounds\n",
      "[10:46:32] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored 0.8076826107844208 in 0:00:30.834416\n",
      "[10:46:33] Training until validation scores don't improve for 100 rounds\n",
      "[10:46:53] \u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored 0.8063334797059143 in 0:00:20.893037\n",
      "[10:46:54] Training until validation scores don't improve for 100 rounds\n",
      "[10:47:18] \u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored 0.8066685359073631 in 0:00:25.334812\n",
      "[10:47:20] Training until validation scores don't improve for 100 rounds\n",
      "[10:47:41] \u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored 0.8035774365867183 in 0:00:22.976742\n",
      "[10:47:43] Training until validation scores don't improve for 100 rounds\n",
      "[10:48:02] \u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored 0.8091982765021324 in 0:00:21.300400\n",
      "[10:48:05] Training until validation scores don't improve for 100 rounds\n",
      "[10:48:23] \u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored 0.806754366331848 in 0:00:21.155740\n",
      "[10:48:25] Training until validation scores don't improve for 100 rounds\n",
      "[10:48:42] \u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored 0.8032777264284059 in 0:00:18.200847\n",
      "[10:48:43] Training until validation scores don't improve for 100 rounds\n",
      "[10:49:08] \u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored 0.8098000015461311 in 0:00:26.820672\n",
      "[10:49:11] Training until validation scores don't improve for 100 rounds\n",
      "[10:49:26] \u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored 0.8018524101577995 in 0:00:18.031300\n",
      "[10:49:28] Training until validation scores don't improve for 100 rounds\n",
      "[10:50:00] \u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939328, 'min_sum_hessian_in_leaf': 5.997863556602811, 'reg_alpha': 7.159256876318376, 'reg_lambda': 0.12319224250434464} scored 0.8097954773559605 in 0:00:33.934555\n",
      "[10:50:02] Training until validation scores don't improve for 100 rounds\n",
      "[10:50:46] \u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.9897525503069795, 'num_leaves': 135, 'bagging_fraction': 0.9913853675644914, 'min_sum_hessian_in_leaf': 9.75862618615181, 'reg_alpha': 9.166783750456993, 'reg_lambda': 0.09582202435248836} scored 0.8091777432415471 in 0:00:45.990575\n",
      "[10:50:48] Training until validation scores don't improve for 100 rounds\n",
      "[10:51:16] \u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.8861890988240213, 'num_leaves': 120, 'bagging_fraction': 0.9982635852231622, 'min_sum_hessian_in_leaf': 1.9606799463014675, 'reg_alpha': 0.265258623705797, 'reg_lambda': 9.542209832778344} scored 0.8099516148842313 in 0:00:29.159265\n",
      "[10:51:18] Training until validation scores don't improve for 100 rounds\n",
      "[10:51:46] \u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.8748256163461332, 'num_leaves': 109, 'bagging_fraction': 0.918102167745622, 'min_sum_hessian_in_leaf': 1.456609683767739, 'reg_alpha': 0.08189076841283618, 'reg_lambda': 4.184017995280893} scored 0.809200098063566 in 0:00:30.509823\n",
      "[10:51:48] Training until validation scores don't improve for 100 rounds\n",
      "[10:52:11] \u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.8505812976968798, 'num_leaves': 165, 'bagging_fraction': 0.7332743686077304, 'min_sum_hessian_in_leaf': 2.0672444231680402, 'reg_alpha': 0.11992227654262412, 'reg_lambda': 0.013109403173644564} scored 0.8052162036844881 in 0:00:24.756458\n",
      "[10:52:13] Training until validation scores don't improve for 100 rounds\n",
      "[10:52:52] \u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.783402910298474, 'num_leaves': 20, 'bagging_fraction': 0.9207925561021314, 'min_sum_hessian_in_leaf': 0.03513566750882195, 'reg_alpha': 0.11275208697885644, 'reg_lambda': 9.786297813785227} scored 0.8092739346041151 in 0:00:41.521029\n",
      "[10:52:55] Training until validation scores don't improve for 100 rounds\n",
      "[10:53:17] \u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.6256697208811228, 'num_leaves': 163, 'bagging_fraction': 0.7176250403204765, 'min_sum_hessian_in_leaf': 1.6352484839413766, 'reg_alpha': 0.004783646643245607, 'reg_lambda': 0.7029231532835138} scored 0.8068961225680062 in 0:00:24.548764\n",
      "[10:53:19] Training until validation scores don't improve for 100 rounds\n",
      "[10:53:48] \u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.9152944777919422, 'num_leaves': 89, 'bagging_fraction': 0.9229467686477492, 'min_sum_hessian_in_leaf': 0.18405066294467862, 'reg_alpha': 0.7073220474194093, 'reg_lambda': 0.012036050876531337} scored 0.8074327235610357 in 0:00:31.035762\n",
      "[10:53:50] Training until validation scores don't improve for 100 rounds\n",
      "[10:54:17] \u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.8494042420610307, 'num_leaves': 169, 'bagging_fraction': 0.9913430783889023, 'min_sum_hessian_in_leaf': 2.8294973231916205, 'reg_alpha': 0.00026934318121584405, 'reg_lambda': 0.006043082249395001} scored 0.8074864583314385 in 0:00:29.286721\n",
      "[10:54:19] Training until validation scores don't improve for 100 rounds\n",
      "[10:54:45] \u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.9199025236538207, 'num_leaves': 105, 'bagging_fraction': 0.9350108553019307, 'min_sum_hessian_in_leaf': 0.7617040566436284, 'reg_alpha': 0.008827139889252714, 'reg_lambda': 0.9771702525675098} scored 0.808001911125413 in 0:00:27.416564\n",
      "[10:54:46] Training until validation scores don't improve for 100 rounds\n",
      "[10:55:06] \u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.7761835039977845, 'num_leaves': 64, 'bagging_fraction': 0.6791951423952709, 'min_sum_hessian_in_leaf': 0.025666323313290235, 'reg_alpha': 0.6849391813641007, 'reg_lambda': 1.0587960834029175} scored 0.8076818873273977 in 0:00:21.198768\n",
      "[10:55:08] Training until validation scores don't improve for 100 rounds\n",
      "[10:55:40] \u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.9781351586141712, 'num_leaves': 137, 'bagging_fraction': 0.9991586586371216, 'min_sum_hessian_in_leaf': 5.530770305256436, 'reg_alpha': 1.3759545863202707, 'reg_lambda': 0.09222242199827665} scored 0.8072787770740355 in 0:00:34.231069\n",
      "[10:55:42] Training until validation scores don't improve for 100 rounds\n",
      "[10:56:10] \u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.9546269431746482, 'num_leaves': 135, 'bagging_fraction': 0.9533976901091019, 'min_sum_hessian_in_leaf': 0.0011721743969143514, 'reg_alpha': 2.3130663759466916, 'reg_lambda': 0.24304737423042483} scored 0.8086127258901539 in 0:00:29.622259\n",
      "[10:56:12] Training until validation scores don't improve for 100 rounds\n",
      "[10:56:32] \u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.8752093362951713, 'num_leaves': 115, 'bagging_fraction': 0.871999300323083, 'min_sum_hessian_in_leaf': 3.718491304610594, 'reg_alpha': 0.0317234323543116, 'reg_lambda': 0.026276084960821452} scored 0.807979863772629 in 0:00:21.919288\n",
      "[10:56:34] Training until validation scores don't improve for 100 rounds\n",
      "[10:57:02] \u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.9497489612648039, 'num_leaves': 195, 'bagging_fraction': 0.8794896849942123, 'min_sum_hessian_in_leaf': 1.1633235706095253, 'reg_alpha': 0.3791113951848487, 'reg_lambda': 1.5286559622851674} scored 0.8078412364880966 in 0:00:30.692801\n",
      "[10:57:04] Training until validation scores don't improve for 100 rounds\n",
      "[10:57:38] \u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.8181258441633572, 'num_leaves': 16, 'bagging_fraction': 0.9624991184633523, 'min_sum_hessian_in_leaf': 0.4500373583275773, 'reg_alpha': 0.0004530781170200388, 'reg_lambda': 0.004543588418305205} scored 0.8069533712725221 in 0:00:36.033363\n",
      "[10:57:42] Training until validation scores don't improve for 100 rounds\n",
      "[10:58:08] \u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.8883886788216927, 'num_leaves': 84, 'bagging_fraction': 0.7969610432359211, 'min_sum_hessian_in_leaf': 2.9927990921913863, 'reg_alpha': 7.489719593232507, 'reg_lambda': 0.06073222383150538} scored 0.8085312749644349 in 0:00:29.862245\n",
      "[10:58:10] Training until validation scores don't improve for 100 rounds\n",
      "[10:58:37] \u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.5938540156231678, 'num_leaves': 119, 'bagging_fraction': 0.963645888059683, 'min_sum_hessian_in_leaf': 8.289884975726087, 'reg_alpha': 0.31826124476428636, 'reg_lambda': 8.805342315913878} scored 0.8098055463274593 in 0:00:28.195529\n",
      "[10:58:38] Training until validation scores don't improve for 100 rounds\n",
      "[10:59:06] \u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.5796220576949027, 'num_leaves': 45, 'bagging_fraction': 0.8916727642931415, 'min_sum_hessian_in_leaf': 9.074966324558188, 'reg_alpha': 0.021445498593251056, 'reg_lambda': 8.822211040651636} scored 0.8089570810981268 in 0:00:29.404295\n",
      "[10:59:08] Training until validation scores don't improve for 100 rounds\n",
      "[10:59:28] \u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6584176056288116, 'num_leaves': 155, 'bagging_fraction': 0.9570251780829498, 'min_sum_hessian_in_leaf': 0.2853459394624822, 'reg_alpha': 0.0007451317524731146, 'reg_lambda': 1.9109717181200059} scored 0.8076474507730903 in 0:00:22.473351\n",
      "[10:59:30] Training until validation scores don't improve for 100 rounds\n",
      "[10:59:51] \u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.7506083652373037, 'num_leaves': 183, 'bagging_fraction': 0.8413254205183562, 'min_sum_hessian_in_leaf': 1.0108975167093213, 'reg_alpha': 5.872992194632268e-05, 'reg_lambda': 1.5544977737472529e-06} scored 0.8061708569021852 in 0:00:23.039371\n",
      "[10:59:53] Training until validation scores don't improve for 100 rounds\n",
      "[11:00:14] \u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5883023827001841, 'num_leaves': 116, 'bagging_fraction': 0.9671665339442991, 'min_sum_hessian_in_leaf': 4.233604388598911, 'reg_alpha': 0.25217045974175795, 'reg_lambda': 0.3762393256843606} scored 0.8084565030973055 in 0:00:22.852522\n",
      "[11:00:16] Training until validation scores don't improve for 100 rounds\n",
      "[11:00:44] \u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.682666181395754, 'num_leaves': 126, 'bagging_fraction': 0.9062721574447062, 'min_sum_hessian_in_leaf': 9.89972344987193, 'reg_alpha': 2.150379786218331, 'reg_lambda': 4.268823427066445} scored 0.8099527982532192 in 0:00:29.439296\n",
      "[11:00:46] Training until validation scores don't improve for 100 rounds\n",
      "[11:01:09] \u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5596077307495221, 'num_leaves': 93, 'bagging_fraction': 0.9104843804118928, 'min_sum_hessian_in_leaf': 2.2568179713284415, 'reg_alpha': 1.363673406705274, 'reg_lambda': 2.920048242645844} scored 0.8085465295725254 in 0:00:25.563523\n",
      "[11:01:11] Training until validation scores don't improve for 100 rounds\n",
      "[11:01:35] \u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.6791339604073288, 'num_leaves': 154, 'bagging_fraction': 0.9540253272876881, 'min_sum_hessian_in_leaf': 9.16775095029316, 'reg_alpha': 0.03793138564016783, 'reg_lambda': 8.294667356727814} scored 0.8095335471569132 in 0:00:26.073388\n",
      "[11:01:37] Training until validation scores don't improve for 100 rounds\n",
      "[11:02:02] \u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.7017823848319402, 'num_leaves': 77, 'bagging_fraction': 0.8378548269496634, 'min_sum_hessian_in_leaf': 4.539690579388666, 'reg_alpha': 0.23876301776330416, 'reg_lambda': 2.3617192445907755} scored 0.8095125643194635 in 0:00:26.631916\n",
      "[11:02:04] Training until validation scores don't improve for 100 rounds\n",
      "[11:02:20] \u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.6199202224818425, 'num_leaves': 99, 'bagging_fraction': 0.8962751458234806, 'min_sum_hessian_in_leaf': 0.637288400001041, 'reg_alpha': 1.1844966857166301, 'reg_lambda': 0.0015415885657535419} scored 0.8083521495892502 in 0:00:17.954055\n",
      "[11:02:22] Training until validation scores don't improve for 100 rounds\n",
      "[11:02:43] \u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.7381212271436373, 'num_leaves': 120, 'bagging_fraction': 0.7740239592384441, 'min_sum_hessian_in_leaf': 2.597360005208981, 'reg_alpha': 2.3100050241414967, 'reg_lambda': 0.3621303954535214} scored 0.808205853660271 in 0:00:22.878796\n",
      "[11:02:45] Training until validation scores don't improve for 100 rounds\n",
      "[11:03:13] \u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.6271273935795475, 'num_leaves': 211, 'bagging_fraction': 0.9457779694177562, 'min_sum_hessian_in_leaf': 0.11608958873108131, 'reg_alpha': 0.006765612106287592, 'reg_lambda': 2.9936787073789606e-08} scored 0.8057408392151078 in 0:00:30.405260\n",
      "[11:03:15] Training until validation scores don't improve for 100 rounds\n",
      "[11:03:34] \u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.5450137502410498, 'num_leaves': 71, 'bagging_fraction': 0.8566686224697246, 'min_sum_hessian_in_leaf': 6.606753894758453, 'reg_alpha': 1.1614088660604218e-06, 'reg_lambda': 5.188531211438814e-05} scored 0.8083567745466487 in 0:00:20.925503\n",
      "[11:03:36] Training until validation scores don't improve for 100 rounds\n",
      "[11:03:56] \u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.5030191128377941, 'num_leaves': 48, 'bagging_fraction': 0.9715295745793016, 'min_sum_hessian_in_leaf': 0.37901512686852395, 'reg_alpha': 0.48284485740229216, 'reg_lambda': 3.1270891136408876} scored 0.8096648623579605 in 0:00:21.735129\n",
      "[11:03:58] Training until validation scores don't improve for 100 rounds\n",
      "[11:04:23] \u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.759359978569621, 'num_leaves': 128, 'bagging_fraction': 0.9837815484630321, 'min_sum_hessian_in_leaf': 5.367134478050795, 'reg_alpha': 3.76393041450372, 'reg_lambda': 0.5620343581812116} scored 0.8099557954323156 in 0:00:27.405187\n",
      "[11:04:25] Training until validation scores don't improve for 100 rounds\n",
      "[11:04:52] \u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.7585630111798157, 'num_leaves': 126, 'bagging_fraction': 0.9991417930830016, 'min_sum_hessian_in_leaf': 4.122113955538323, 'reg_alpha': 2.726122110398838, 'reg_lambda': 0.40716159584776573} scored 0.8095114998041291 in 0:00:28.137072\n",
      "[11:04:53] Training until validation scores don't improve for 100 rounds\n",
      "[11:05:23] \u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.671927353778549, 'num_leaves': 148, 'bagging_fraction': 0.931024209185708, 'min_sum_hessian_in_leaf': 6.763507374393761, 'reg_alpha': 4.260450190333637, 'reg_lambda': 4.507341123524574} scored 0.8103479220577995 in 0:00:31.330210\n",
      "[11:05:25] Training until validation scores don't improve for 100 rounds\n",
      "[11:06:00] \u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.7125465112085845, 'num_leaves': 143, 'bagging_fraction': 0.9317137267342335, 'min_sum_hessian_in_leaf': 7.315333825795606, 'reg_alpha': 9.283885669246942, 'reg_lambda': 4.820216136637764} scored 0.8094171868460465 in 0:00:36.671654\n",
      "[11:06:01] Training until validation scores don't improve for 100 rounds\n",
      "[11:06:25] \u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.6811563970407595, 'num_leaves': 150, 'bagging_fraction': 0.8985003155988937, 'min_sum_hessian_in_leaf': 5.519301878720605, 'reg_alpha': 0.16732337453296012, 'reg_lambda': 0.6956632632696087} scored 0.8078482824427482 in 0:00:25.045314\n",
      "[11:06:27] Training until validation scores don't improve for 100 rounds\n",
      "[11:06:59] \u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.6478698683834716, 'num_leaves': 254, 'bagging_fraction': 0.9733132286954291, 'min_sum_hessian_in_leaf': 9.534895669494576, 'reg_alpha': 3.3351364724980233, 'reg_lambda': 0.04664784285813119} scored 0.809169152189396 in 0:00:33.955405\n",
      "[11:07:01] Training until validation scores don't improve for 100 rounds\n",
      "[11:07:26] \u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.6012536186354468, 'num_leaves': 126, 'bagging_fraction': 0.8239571203711424, 'min_sum_hessian_in_leaf': 1.8533193372802301, 'reg_alpha': 0.07939836077981922, 'reg_lambda': 4.18668737628779} scored 0.8099497028906696 in 0:00:27.100262\n",
      "[11:07:28] Training until validation scores don't improve for 100 rounds\n",
      "[11:07:51] \u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.6933239527663485, 'num_leaves': 177, 'bagging_fraction': 0.8288554742129679, 'min_sum_hessian_in_leaf': 2.005263456413838, 'reg_alpha': 0.061092681782855505, 'reg_lambda': 9.608193156458084e-05} scored 0.8065951231059276 in 0:00:24.887723\n",
      "[11:07:53] Training until validation scores don't improve for 100 rounds\n",
      "[11:08:16] \u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.7260444793055765, 'num_leaves': 143, 'bagging_fraction': 0.8753398828078675, 'min_sum_hessian_in_leaf': 0.7498582478973057, 'reg_alpha': 0.013148601660640021, 'reg_lambda': 2.672388891835771} scored 0.8082542400162518 in 0:00:24.831904\n",
      "[11:08:17] Training until validation scores don't improve for 100 rounds\n",
      "[11:08:41] \u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.6675522426703349, 'num_leaves': 106, 'bagging_fraction': 0.8022568646083734, 'min_sum_hessian_in_leaf': 1.593783865654356, 'reg_alpha': 0.8683903615930498, 'reg_lambda': 0.16967592207859775} scored 0.8089773818189545 in 0:00:25.371466\n",
      "[11:08:43] Training until validation scores don't improve for 100 rounds\n",
      "[11:09:09] \u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.6123039364937721, 'num_leaves': 127, 'bagging_fraction': 0.9388110002137479, 'min_sum_hessian_in_leaf': 3.7243844170065215, 'reg_alpha': 0.33126661737888385, 'reg_lambda': 8.673097126655854} scored 0.8098117008797073 in 0:00:27.854864\n",
      "[11:09:11] Training until validation scores don't improve for 100 rounds\n",
      "[11:09:41] \u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.609627438753299, 'num_leaves': 129, 'bagging_fraction': 0.9389869170525047, 'min_sum_hessian_in_leaf': 3.3823344849748382, 'reg_alpha': 3.940200341760198, 'reg_lambda': 4.261522332609968} scored 0.8098554751971647 in 0:00:32.250044\n",
      "[11:09:43] Training until validation scores don't improve for 100 rounds\n",
      "[11:10:08] \u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.6409343927673509, 'num_leaves': 146, 'bagging_fraction': 0.9127923462204717, 'min_sum_hessian_in_leaf': 2.885265936415204, 'reg_alpha': 4.652183863011177, 'reg_lambda': 0.9876657186022971} scored 0.8094592687908246 in 0:00:26.507692\n",
      "[11:10:09] Training until validation scores don't improve for 100 rounds\n",
      "[11:10:39] \u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.5512161448329317, 'num_leaves': 129, 'bagging_fraction': 0.8588861486540558, 'min_sum_hessian_in_leaf': 5.0949438218574805, 'reg_alpha': 4.53630268967216, 'reg_lambda': 3.688154372317033} scored 0.8095499076207392 in 0:00:30.954013\n",
      "[11:10:40] Training until validation scores don't improve for 100 rounds\n",
      "[11:11:02] \u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.6012290102463753, 'num_leaves': 159, 'bagging_fraction': 0.8185209285713998, 'min_sum_hessian_in_leaf': 1.9447490672383523, 'reg_alpha': 1.586200781141248, 'reg_lambda': 0.5343226327450117} scored 0.8074529855252373 in 0:00:23.922863\n",
      "[11:11:04] Training until validation scores don't improve for 100 rounds\n",
      "[11:11:24] \u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.5735495947448853, 'num_leaves': 97, 'bagging_fraction': 0.7752273675679812, 'min_sum_hessian_in_leaf': 1.1033213135007145, 'reg_alpha': 0.09058754011625061, 'reg_lambda': 1.5257627886424208} scored 0.8078360844405807 in 0:00:21.241083\n",
      "[11:11:26] Training until validation scores don't improve for 100 rounds\n",
      "[11:11:49] \u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.8114743396926144, 'num_leaves': 110, 'bagging_fraction': 0.6634317166775692, 'min_sum_hessian_in_leaf': 6.277303576434502, 'reg_alpha': 0.7189434571939906, 'reg_lambda': 0.18707395905172433} scored 0.807367984492554 in 0:00:24.994965\n",
      "[11:11:51] Training until validation scores don't improve for 100 rounds\n",
      "[11:12:25] \u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.6392625871015173, 'num_leaves': 135, 'bagging_fraction': 0.9799972318106991, 'min_sum_hessian_in_leaf': 0.018442348452652888, 'reg_alpha': 9.346128747155287, 'reg_lambda': 4.666049495615872} scored 0.8097333789056137 in 0:00:36.164721\n",
      "[11:12:27] Training until validation scores don't improve for 100 rounds\n",
      "[11:12:48] \u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.5296951513802125, 'num_leaves': 176, 'bagging_fraction': 0.9299788866889858, 'min_sum_hessian_in_leaf': 3.5106098082871084, 'reg_alpha': 0.0029565231289047245, 'reg_lambda': 1.3652803483082798} scored 0.8090040257076112 in 0:00:23.482235\n",
      "[11:12:50] Training until validation scores don't improve for 100 rounds\n",
      "[11:13:18] \u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.6731770655681039, 'num_leaves': 125, 'bagging_fraction': 0.9004122867054367, 'min_sum_hessian_in_leaf': 1.408582401943456, 'reg_alpha': 1.473170045026956e-05, 'reg_lambda': 4.2658746467424535} scored 0.8099932679223455 in 0:00:29.461778\n",
      "[11:13:20] Training until validation scores don't improve for 100 rounds\n",
      "[11:13:43] \u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.7094390040638918, 'num_leaves': 125, 'bagging_fraction': 0.8998765782586333, 'min_sum_hessian_in_leaf': 1.4076524380315791, 'reg_alpha': 8.636780089163073e-05, 'reg_lambda': 4.393600860960379} scored 0.8084936138588239 in 0:00:25.492494\n",
      "[11:13:45] Training until validation scores don't improve for 100 rounds\n",
      "[11:14:06] \u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.6688602285183876, 'num_leaves': 137, 'bagging_fraction': 0.9449114343855813, 'min_sum_hessian_in_leaf': 2.3304755489576734, 'reg_alpha': 8.47399145454219e-06, 'reg_lambda': 0.7765492127489164} scored 0.8088382972062323 in 0:00:22.293816\n",
      "[11:14:08] Training until validation scores don't improve for 100 rounds\n",
      "[11:14:32] \u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.845959907224959, 'num_leaves': 112, 'bagging_fraction': 0.88529538928992, 'min_sum_hessian_in_leaf': 0.9040369352901069, 'reg_alpha': 2.113465555967829e-05, 'reg_lambda': 1.7414656858073523} scored 0.8077279250318279 in 0:00:26.103218\n",
      "[11:14:34] Training until validation scores don't improve for 100 rounds\n",
      "[11:14:58] \u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.6071685561693618, 'num_leaves': 166, 'bagging_fraction': 0.505139687665829, 'min_sum_hessian_in_leaf': 3.189528694067513, 'reg_alpha': 1.9913449901121965e-06, 'reg_lambda': 5.577172290885319} scored 0.8071569856679444 in 0:00:25.820955\n",
      "[11:15:00] Training until validation scores don't improve for 100 rounds\n",
      "[11:15:28] \u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.6301131781788495, 'num_leaves': 101, 'bagging_fraction': 0.9149172693059456, 'min_sum_hessian_in_leaf': 1.694748864400194, 'reg_alpha': 1.8965025977773572e-07, 'reg_lambda': 9.597134543399704} scored 0.8100820619368507 in 0:00:30.801509\n",
      "[11:15:30] Training until validation scores don't improve for 100 rounds\n",
      "[11:15:53] \u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.6609667370262164, 'num_leaves': 102, 'bagging_fraction': 0.9137675623411222, 'min_sum_hessian_in_leaf': 1.6175551563557167, 'reg_alpha': 5.861575863463529e-08, 'reg_lambda': 9.041807561611673} scored 0.8103668223725322 in 0:00:24.657830\n",
      "[11:15:55] Training until validation scores don't improve for 100 rounds\n",
      "[11:16:15] \u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.6898501785546203, 'num_leaves': 100, 'bagging_fraction': 0.9117501321800316, 'min_sum_hessian_in_leaf': 0.6026578832132712, 'reg_alpha': 1.2340673724948323e-08, 'reg_lambda': 1.9467450057792335} scored 0.8086453925585294 in 0:00:21.718324\n",
      "[11:16:17] Training until validation scores don't improve for 100 rounds\n",
      "[11:16:57] \u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.7290252527543974, 'num_leaves': 86, 'bagging_fraction': 0.9884232865589057, 'min_sum_hessian_in_leaf': 0.011154341843528447, 'reg_alpha': 1.0159827880965956e-07, 'reg_lambda': 9.082431682107702} scored 0.8094980848438978 in 0:00:42.568087\n",
      "[11:16:59] Training until validation scores don't improve for 100 rounds\n",
      "[11:17:23] \u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.7921722475066958, 'num_leaves': 103, 'bagging_fraction': 0.854429129886631, 'min_sum_hessian_in_leaf': 0.051743092098014226, 'reg_alpha': 3.6248901021881555e-08, 'reg_lambda': 0.26634334787505654} scored 0.8070273085802996 in 0:00:25.900171\n",
      "[11:17:26] Training until validation scores don't improve for 100 rounds\n",
      "[11:17:42] \u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.6593892689662274, 'num_leaves': 80, 'bagging_fraction': 0.9279136388572679, 'min_sum_hessian_in_leaf': 0.2425691153676186, 'reg_alpha': 7.938618239857861e-07, 'reg_lambda': 6.8566766423369545e-06} scored 0.8076232537194373 in 0:00:18.442895\n",
      "[11:17:44] Training until validation scores don't improve for 100 rounds\n",
      "[11:18:07] \u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.6312826633461579, 'num_leaves': 119, 'bagging_fraction': 0.8697828329087357, 'min_sum_hessian_in_leaf': 1.5978182768899547, 'reg_alpha': 2.867567604375617e-07, 'reg_lambda': 9.872832113515903} scored 0.8097765951276533 in 0:00:24.864161\n",
      "[11:18:09] Training until validation scores don't improve for 100 rounds\n",
      "[11:18:32] \u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.6737144812890428, 'num_leaves': 91, 'bagging_fraction': 0.9098676402964456, 'min_sum_hessian_in_leaf': 7.323410972599962, 'reg_alpha': 6.117499533948563e-08, 'reg_lambda': 0.9894127297413398} scored 0.8095701876713662 in 0:00:25.018024\n",
      "[11:18:34] Training until validation scores don't improve for 100 rounds\n",
      "[11:18:57] \u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.7632711976367786, 'num_leaves': 139, 'bagging_fraction': 0.955385145389234, 'min_sum_hessian_in_leaf': 1.304539532378556, 'reg_alpha': 2.6587476757100515e-07, 'reg_lambda': 2.280345290541442} scored 0.8082869867816547 in 0:00:25.236490\n",
      "[11:18:59] Training until validation scores don't improve for 100 rounds\n",
      "[11:19:28] \u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.6511351777350247, 'num_leaves': 121, 'bagging_fraction': 0.9820013480881271, 'min_sum_hessian_in_leaf': 4.978628883167738, 'reg_alpha': 5.849967942534989e-07, 'reg_lambda': 5.186108599209899} scored 0.8105929285300527 in 0:00:31.280626\n",
      "[11:19:30] Training until validation scores don't improve for 100 rounds\n",
      "[11:20:00] \u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.6502312200938172, 'num_leaves': 113, 'bagging_fraction': 0.9782057381859461, 'min_sum_hessian_in_leaf': 4.864675882551464, 'reg_alpha': 5.055926785303915e-07, 'reg_lambda': 5.846517077359751} scored 0.8104518208214403 in 0:00:31.911069\n",
      "[11:20:02] Training until validation scores don't improve for 100 rounds\n",
      "[11:20:28] \u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.6500039517701169, 'num_leaves': 112, 'bagging_fraction': 0.9774207619811073, 'min_sum_hessian_in_leaf': 4.990817458666577, 'reg_alpha': 5.53909656469509e-07, 'reg_lambda': 0.6367803970887633} scored 0.809431317511976 in 0:00:27.401854\n",
      "[11:20:29] Training until validation scores don't improve for 100 rounds\n",
      "[11:20:51] \u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.6909406390012688, 'num_leaves': 118, 'bagging_fraction': 0.5963252191423781, 'min_sum_hessian_in_leaf': 9.960496906529, 'reg_alpha': 2.8209656348979746e-06, 'reg_lambda': 6.1446101663858705} scored 0.8081183928737086 in 0:00:23.743167\n",
      "[11:20:53] Training until validation scores don't improve for 100 rounds\n",
      "[11:21:17] \u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.6636416237203868, 'num_leaves': 94, 'bagging_fraction': 0.95365546369094, 'min_sum_hessian_in_leaf': 0.0012752738577831212, 'reg_alpha': 1.5130813717986447e-07, 'reg_lambda': 2.65031129188709} scored 0.809597384487891 in 0:00:25.255338\n",
      "[11:21:19] Training until validation scores don't improve for 100 rounds\n",
      "[11:21:43] \u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.7413272226457542, 'num_leaves': 149, 'bagging_fraction': 0.9891121506532701, 'min_sum_hessian_in_leaf': 5.714155661828098, 'reg_alpha': 3.286336587831236e-08, 'reg_lambda': 0.10488207508886738} scored 0.8083318979601488 in 0:00:26.133304\n",
      "[11:21:45] Training until validation scores don't improve for 100 rounds\n",
      "[11:22:08] \u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.7006523813480485, 'num_leaves': 73, 'bagging_fraction': 0.9676188280633804, 'min_sum_hessian_in_leaf': 7.290023145200372, 'reg_alpha': 9.26385775632999e-06, 'reg_lambda': 1.4757664697877884} scored 0.8091817894333273 in 0:00:24.755193\n",
      "[11:22:09] Training until validation scores don't improve for 100 rounds\n",
      "[11:22:34] \u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.6334064099538151, 'num_leaves': 122, 'bagging_fraction': 0.9932421181621519, 'min_sum_hessian_in_leaf': 2.4369770661120675, 'reg_alpha': 4.460122672178311e-07, 'reg_lambda': 6.165249745603739} scored 0.8095377018672466 in 0:00:26.729801\n",
      "[11:22:36] Training until validation scores don't improve for 100 rounds\n",
      "[11:23:01] \u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.9068580862161011, 'num_leaves': 106, 'bagging_fraction': 0.9208605925402463, 'min_sum_hessian_in_leaf': 4.635024781280816, 'reg_alpha': 8.283489996666706e-08, 'reg_lambda': 3.1986082834965917} scored 0.808245041776956 in 0:00:26.668223\n",
      "[11:23:03] Training until validation scores don't improve for 100 rounds\n",
      "[11:23:30] \u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.651566955964599, 'num_leaves': 133, 'bagging_fraction': 0.9997441430609754, 'min_sum_hessian_in_leaf': 4.367095995351109, 'reg_alpha': 1.918341198440864e-08, 'reg_lambda': 6.3842358203086995} scored 0.8099604798165413 in 0:00:29.371754\n",
      "[11:23:32] Training until validation scores don't improve for 100 rounds\n",
      "[11:24:01] \u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.6539839799250678, 'num_leaves': 133, 'bagging_fraction': 0.9778841289725848, 'min_sum_hessian_in_leaf': 7.541664591665945, 'reg_alpha': 1.4518220781616373e-08, 'reg_lambda': 5.873416048390669} scored 0.8105668685745647 in 0:00:30.306405\n",
      "[11:24:03] Training until validation scores don't improve for 100 rounds\n",
      "[11:24:28] \u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.651226271837219, 'num_leaves': 132, 'bagging_fraction': 0.9806738533689935, 'min_sum_hessian_in_leaf': 4.160512400786632, 'reg_alpha': 1.4259434309518455e-08, 'reg_lambda': 6.0149169128900155} scored 0.8098195400533094 in 0:00:26.946830\n",
      "[11:24:30] Training until validation scores don't improve for 100 rounds\n",
      "[11:24:55] \u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.6239140917825684, 'num_leaves': 154, 'bagging_fraction': 0.963160611808918, 'min_sum_hessian_in_leaf': 2.883868938715232, 'reg_alpha': 2.368176423194508e-08, 'reg_lambda': 9.921729612265047} scored 0.8089084182782119 in 0:00:27.705846\n",
      "[11:24:57] Training until validation scores don't improve for 100 rounds\n",
      "[11:25:21] \u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.7202092993749813, 'num_leaves': 144, 'bagging_fraction': 0.9436799671488917, 'min_sum_hessian_in_leaf': 7.2004566326340145, 'reg_alpha': 5.77112971401817e-08, 'reg_lambda': 0.46103190581963766} scored 0.8089680414720292 in 0:00:25.800319\n",
      "[11:25:25] Training until validation scores don't improve for 100 rounds\n",
      "[11:25:45] \u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.6425031662210405, 'num_leaves': 116, 'bagging_fraction': 0.9999155991182738, 'min_sum_hessian_in_leaf': 5.601171296971892, 'reg_alpha': 1.844132428016218e-07, 'reg_lambda': 0.0009400527794458898} scored 0.8084109046346393 in 0:00:23.492537\n",
      "[11:25:47] Training until validation scores don't improve for 100 rounds\n",
      "[11:26:15] \u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.6751344983480173, 'num_leaves': 138, 'bagging_fraction': 0.9741986201343052, 'min_sum_hessian_in_leaf': 3.521981024583811, 'reg_alpha': 1.9952575939649075e-08, 'reg_lambda': 1.015474852233211} scored 0.8097549172547063 in 0:00:30.477915\n",
      "[11:26:17] Training until validation scores don't improve for 100 rounds\n",
      "[11:26:36] \u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.5841202413482005, 'num_leaves': 108, 'bagging_fraction': 0.94943307220291, 'min_sum_hessian_in_leaf': 2.4908313704913905, 'reg_alpha': 4.719519368911754e-08, 'reg_lambda': 8.989280366318637e-08} scored 0.8074200914846545 in 0:00:21.172963\n",
      "[11:26:38] Training until validation scores don't improve for 100 rounds\n",
      "[11:27:01] \u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.6581514413861924, 'num_leaves': 132, 'bagging_fraction': 0.8855299819393142, 'min_sum_hessian_in_leaf': 8.647070815553485, 'reg_alpha': 1.4155986110389421e-06, 'reg_lambda': 2.6972960799951786} scored 0.8095343377920885 in 0:00:24.424531\n",
      "[11:27:03] Training until validation scores don't improve for 100 rounds\n",
      "[11:27:24] \u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.702954339705586, 'num_leaves': 123, 'bagging_fraction': 0.9006065382423908, 'min_sum_hessian_in_leaf': 6.379441034129152, 'reg_alpha': 9.838441808093156e-08, 'reg_lambda': 3.5276031178598704} scored 0.8088261147067154 in 0:00:23.221154\n",
      "[11:27:26] Training until validation scores don't improve for 100 rounds\n",
      "[11:27:51] \u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.6825193890530799, 'num_leaves': 141, 'bagging_fraction': 0.9257322747603033, 'min_sum_hessian_in_leaf': 4.581348902255347, 'reg_alpha': 4.205405719123183e-06, 'reg_lambda': 6.599668200941844} scored 0.8088375840843094 in 0:00:27.043484\n",
      "[11:27:53] Training until validation scores don't improve for 100 rounds\n",
      "[11:28:16] \u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.6185087987175221, 'num_leaves': 160, 'bagging_fraction': 0.9635069200077563, 'min_sum_hessian_in_leaf': 8.002449883202534, 'reg_alpha': 5.36513542510868e-07, 'reg_lambda': 1.520252348203348} scored 0.807876334488825 in 0:00:24.617588\n",
      "[11:28:18] Training until validation scores don't improve for 100 rounds\n",
      "[11:28:46] \u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.6507547694872173, 'num_leaves': 101, 'bagging_fraction': 0.9902073707753263, 'min_sum_hessian_in_leaf': 3.9762009323921705, 'reg_alpha': 0.00012449732571863682, 'reg_lambda': 5.293372776120325} scored 0.809573538827649 in 0:00:29.999470\n",
      "[11:28:48] Training until validation scores don't improve for 100 rounds\n",
      "[11:29:15] \u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.6687559101472682, 'num_leaves': 113, 'bagging_fraction': 0.940351009440782, 'min_sum_hessian_in_leaf': 0.52977523488027, 'reg_alpha': 0.0011402204193789321, 'reg_lambda': 2.302559294709624} scored 0.8095528557081091 in 0:00:29.248030\n",
      "[11:29:17] Training until validation scores don't improve for 100 rounds\n",
      "[11:29:39] \u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.6367061372884992, 'num_leaves': 131, 'bagging_fraction': 0.6175671957913176, 'min_sum_hessian_in_leaf': 6.0396216686006685, 'reg_alpha': 1.0374546221257818e-08, 'reg_lambda': 0.28977570442932493} scored 0.8088653906717533 in 0:00:23.758282\n",
      "[11:29:41] Training until validation scores don't improve for 100 rounds\n",
      "[11:30:03] \u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.6853061581534283, 'num_leaves': 153, 'bagging_fraction': 0.9834768817270175, 'min_sum_hessian_in_leaf': 0.13619341224442322, 'reg_alpha': 1.957035298712614e-07, 'reg_lambda': 0.6714206330178542} scored 0.8086909961887457 in 0:00:23.885614\n",
      "[11:30:05] Training until validation scores don't improve for 100 rounds\n",
      "[11:30:28] \u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.7371337132138968, 'num_leaves': 96, 'bagging_fraction': 0.9708452317521536, 'min_sum_hessian_in_leaf': 0.850982653610598, 'reg_alpha': 2.1665603475122925e-05, 'reg_lambda': 3.846843562249681} scored 0.8086362873351365 in 0:00:25.294738\n",
      "[11:30:30] Training until validation scores don't improve for 100 rounds\n",
      "[11:30:58] \u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.6981565416770236, 'num_leaves': 120, 'bagging_fraction': 0.5712043648326737, 'min_sum_hessian_in_leaf': 1.8100834356374607, 'reg_alpha': 3.899822755727417e-07, 'reg_lambda': 1.2588481842090327} scored 0.8075055007538008 in 0:00:30.283631\n",
      "[11:31:00] Training until validation scores don't improve for 100 rounds\n",
      "[11:31:35] \u001b[1mTrial 102\u001b[0m with hyperparameters {'feature_fraction': 0.960944367658006, 'num_leaves': 124, 'bagging_fraction': 0.7064025123573497, 'min_sum_hessian_in_leaf': 1.0682181631894705, 'reg_alpha': 6.364478935502911, 'reg_lambda': 7.096238408766306} scored 0.8087627036986266 in 0:00:36.515695\n",
      "[11:31:37] Training until validation scores don't improve for 100 rounds\n",
      "[11:32:00] \u001b[1mTrial 103\u001b[0m with hyperparameters {'feature_fraction': 0.5950236034938796, 'num_leaves': 147, 'bagging_fraction': 0.9976042415387931, 'min_sum_hessian_in_leaf': 9.821907402824005, 'reg_alpha': 2.0938265285976922, 'reg_lambda': 2.0849045997515305} scored 0.8095130784907051 in 0:00:24.929856\n",
      "[11:32:02] Training until validation scores don't improve for 100 rounds\n",
      "[11:32:27] \u001b[1mTrial 104\u001b[0m with hyperparameters {'feature_fraction': 0.6193331342901344, 'num_leaves': 133, 'bagging_fraction': 0.9585195511344312, 'min_sum_hessian_in_leaf': 2.876501413669588, 'reg_alpha': 2.0753874303074326e-08, 'reg_lambda': 3.7274741061457046} scored 0.8090771723802133 in 0:00:27.224367\n",
      "[11:32:29] Training until validation scores don't improve for 100 rounds\n",
      "[11:32:57] \u001b[1mTrial 105\u001b[0m with hyperparameters {'feature_fraction': 0.8316565979400625, 'num_leaves': 115, 'bagging_fraction': 0.9824972587818587, 'min_sum_hessian_in_leaf': 2.216742859444772, 'reg_alpha': 1.0019612097374366, 'reg_lambda': 5.892546144645259} scored 0.8089244609377029 in 0:00:29.800556\n",
      "[11:32:59] Training until validation scores don't improve for 100 rounds\n",
      "[11:33:38] \u001b[1mTrial 106\u001b[0m with hyperparameters {'feature_fraction': 0.9329015102208047, 'num_leaves': 103, 'bagging_fraction': 0.933237113269756, 'min_sum_hessian_in_leaf': 4.88818738082874, 'reg_alpha': 9.679675810089353e-07, 'reg_lambda': 8.817533602878916} scored 0.8092365112058119 in 0:00:40.556496\n",
      "[11:33:39] Training until validation scores don't improve for 100 rounds\n",
      "[11:34:05] \u001b[1mTrial 107\u001b[0m with hyperparameters {'feature_fraction': 0.6613818380864025, 'num_leaves': 127, 'bagging_fraction': 0.9062881741952756, 'min_sum_hessian_in_leaf': 3.2636921444609768, 'reg_alpha': 3.987079246243042e-08, 'reg_lambda': 3.1997503573254398} scored 0.8098896378713133 in 0:00:27.045390\n",
      "[11:34:06] Training until validation scores don't improve for 100 rounds\n",
      "[11:34:27] \u001b[1mTrial 108\u001b[0m with hyperparameters {'feature_fraction': 0.5692401040197504, 'num_leaves': 108, 'bagging_fraction': 0.91900895442093, 'min_sum_hessian_in_leaf': 1.4224392321933148, 'reg_alpha': 0.49063601989507594, 'reg_lambda': 9.888743309411686e-07} scored 0.8079332498863553 in 0:00:21.983210\n",
      "[11:34:29] Training until validation scores don't improve for 100 rounds\n",
      "[11:34:50] \u001b[1mTrial 109\u001b[0m with hyperparameters {'feature_fraction': 0.674979239844286, 'num_leaves': 89, 'bagging_fraction': 0.8872362452775353, 'min_sum_hessian_in_leaf': 8.422804938953636, 'reg_alpha': 1.2888395232687614e-07, 'reg_lambda': 1.0032430574518947} scored 0.8095246977272536 in 0:00:23.521574\n",
      "[11:34:52] Training until validation scores don't improve for 100 rounds\n",
      "[11:35:24] \u001b[1mTrial 110\u001b[0m with hyperparameters {'feature_fraction': 0.8674965631307576, 'num_leaves': 140, 'bagging_fraction': 0.9478198366942192, 'min_sum_hessian_in_leaf': 6.698080657206826, 'reg_alpha': 5.95834389619713, 'reg_lambda': 0.0031405041755549353} scored 0.8083619989398667 in 0:00:33.701185\n",
      "[11:35:26] Training until validation scores don't improve for 100 rounds\n",
      "[11:35:47] \u001b[1mTrial 111\u001b[0m with hyperparameters {'feature_fraction': 0.6435608392346679, 'num_leaves': 122, 'bagging_fraction': 0.9734583487733689, 'min_sum_hessian_in_leaf': 4.088078261452565, 'reg_alpha': 1.6038005282492127, 'reg_lambda': 2.0726433476959043} scored 0.8090163916551587 in 0:00:22.855690\n",
      "[11:35:49] Training until validation scores don't improve for 100 rounds\n",
      "[11:36:22] \u001b[1mTrial 112\u001b[0m with hyperparameters {'feature_fraction': 0.632551689696062, 'num_leaves': 127, 'bagging_fraction': 0.7683719191843994, 'min_sum_hessian_in_leaf': 1.6419033269721983, 'reg_alpha': 2.892035266450492, 'reg_lambda': 4.7425578758068445} scored 0.8087311325508864 in 0:00:35.214828\n",
      "[11:36:24] Training until validation scores don't improve for 100 rounds\n",
      "[11:36:54] \u001b[1mTrial 113\u001b[0m with hyperparameters {'feature_fraction': 0.9984325435524664, 'num_leaves': 136, 'bagging_fraction': 0.7915127606852908, 'min_sum_hessian_in_leaf': 1.899176275655048, 'reg_alpha': 6.719873832713821e-08, 'reg_lambda': 4.322212435802856} scored 0.8091694157344544 in 0:00:32.425292\n",
      "[11:36:56] Training until validation scores don't improve for 100 rounds\n",
      "[11:37:20] \u001b[1mTrial 114\u001b[0m with hyperparameters {'feature_fraction': 0.612281093515423, 'num_leaves': 111, 'bagging_fraction': 0.8654626496544956, 'min_sum_hessian_in_leaf': 1.2178524400561068, 'reg_alpha': 0.06406260638931299, 'reg_lambda': 6.8070793633904545} scored 0.8096505559953255 in 0:00:25.273778\n",
      "[11:37:22] Training until validation scores don't improve for 100 rounds\n",
      "[11:37:46] \u001b[1mTrial 115\u001b[0m with hyperparameters {'feature_fraction': 0.7111145914013698, 'num_leaves': 118, 'bagging_fraction': 0.816713662014532, 'min_sum_hessian_in_leaf': 5.205819573920273, 'reg_alpha': 3.2577309636379616e-08, 'reg_lambda': 1.8756336898178434} scored 0.8086346983134606 in 0:00:26.027899\n",
      "[11:37:48] Training until validation scores don't improve for 100 rounds\n",
      "[11:38:05] \u001b[1mTrial 116\u001b[0m with hyperparameters {'feature_fraction': 0.5996525453716804, 'num_leaves': 127, 'bagging_fraction': 0.8780362131119664, 'min_sum_hessian_in_leaf': 2.0756313850509, 'reg_alpha': 0.028487852836586527, 'reg_lambda': 0.00028569070012326927} scored 0.8072782525676937 in 0:00:19.395715\n",
      "[11:38:07] Training until validation scores don't improve for 100 rounds\n",
      "[11:38:31] \u001b[1mTrial 117\u001b[0m with hyperparameters {'feature_fraction': 0.6580373195696105, 'num_leaves': 115, 'bagging_fraction': 0.9616104176504586, 'min_sum_hessian_in_leaf': 2.645464212100737, 'reg_alpha': 0.2011090741504668, 'reg_lambda': 9.468955994128306} scored 0.8101904202962851 in 0:00:25.520958\n",
      "[11:38:33] Training until validation scores don't improve for 100 rounds\n",
      "[11:38:57] \u001b[1mTrial 118\u001b[0m with hyperparameters {'feature_fraction': 0.6475955969262218, 'num_leaves': 99, 'bagging_fraction': 0.9586786065946756, 'min_sum_hessian_in_leaf': 2.854940202246635, 'reg_alpha': 0.14983664338222447, 'reg_lambda': 9.396442293454822} scored 0.8094539901383299 in 0:00:25.808704\n",
      "[11:38:58] Training until validation scores don't improve for 100 rounds\n",
      "[11:39:25] \u001b[1mTrial 119\u001b[0m with hyperparameters {'feature_fraction': 0.6648238253354956, 'num_leaves': 115, 'bagging_fraction': 0.9370201836287917, 'min_sum_hessian_in_leaf': 3.4531375395636066, 'reg_alpha': 3.223091283333743e-05, 'reg_lambda': 9.705544871096254} scored 0.8097787680824983 in 0:00:28.676221\n",
      "[11:39:27] Training until validation scores don't improve for 100 rounds\n",
      "[11:39:49] \u001b[1mTrial 120\u001b[0m with hyperparameters {'feature_fraction': 0.6560103277613046, 'num_leaves': 106, 'bagging_fraction': 0.9840017478187222, 'min_sum_hessian_in_leaf': 2.5264010158180477, 'reg_alpha': 1.8642061195552378e-08, 'reg_lambda': 2.913397378487299} scored 0.8099148710187747 in 0:00:23.430592\n",
      "[11:39:51] Training until validation scores don't improve for 100 rounds\n",
      "[11:40:09] \u001b[1mTrial 121\u001b[0m with hyperparameters {'feature_fraction': 0.6809533494851593, 'num_leaves': 81, 'bagging_fraction': 0.9703106365875165, 'min_sum_hessian_in_leaf': 6.22980374470862, 'reg_alpha': 0.00017826307524578013, 'reg_lambda': 0.01892350235286114} scored 0.8080738615101516 in 0:00:20.260190\n",
      "[11:40:11] Training until validation scores don't improve for 100 rounds\n",
      "[11:40:35] \u001b[1mTrial 122\u001b[0m with hyperparameters {'feature_fraction': 0.6258854594033433, 'num_leaves': 132, 'bagging_fraction': 0.9921089570429166, 'min_sum_hessian_in_leaf': 4.148963516072768, 'reg_alpha': 0.012344354516735961, 'reg_lambda': 4.8455281355352895} scored 0.8095164270632127 in 0:00:25.932747\n",
      "[11:40:37] Training until validation scores don't improve for 100 rounds\n",
      "[11:41:05] \u001b[1mTrial 123\u001b[0m with hyperparameters {'feature_fraction': 0.6383043260004204, 'num_leaves': 121, 'bagging_fraction': 0.9161981608637877, 'min_sum_hessian_in_leaf': 7.852438581330247, 'reg_alpha': 0.2589164529190998, 'reg_lambda': 6.001549075841049} scored 0.809746416634683 in 0:00:29.518396\n",
      "[11:41:06] Training until validation scores don't improve for 100 rounds\n",
      "[11:41:35] \u001b[1mTrial 124\u001b[0m with hyperparameters {'feature_fraction': 0.672191238946797, 'num_leaves': 113, 'bagging_fraction': 0.9513058850862566, 'min_sum_hessian_in_leaf': 0.9531027300355382, 'reg_alpha': 0.17691688267018685, 'reg_lambda': 3.027698076771493} scored 0.8093246231036951 in 0:00:30.913371\n",
      "[11:41:37] Training until validation scores don't improve for 100 rounds\n",
      "[11:42:16] \u001b[1mTrial 125\u001b[0m with hyperparameters {'feature_fraction': 0.691544790602839, 'num_leaves': 32, 'bagging_fraction': 0.9995754239980366, 'min_sum_hessian_in_leaf': 1.9140037447412732, 'reg_alpha': 2.9128769896358534e-07, 'reg_lambda': 1.3148705591710563} scored 0.8086403231918162 in 0:00:40.482802\n",
      "[11:42:18] Training until validation scores don't improve for 100 rounds\n",
      "[11:42:42] \u001b[1mTrial 126\u001b[0m with hyperparameters {'feature_fraction': 0.6543601448680708, 'num_leaves': 142, 'bagging_fraction': 0.8929659899513737, 'min_sum_hessian_in_leaf': 1.427898644258424, 'reg_alpha': 0.4008513253378878, 'reg_lambda': 4.699530456648953} scored 0.8088317938443482 in 0:00:25.734597\n",
      "[11:42:44] Training until validation scores don't improve for 100 rounds\n",
      "[11:43:09] \u001b[1mTrial 127\u001b[0m with hyperparameters {'feature_fraction': 0.6283852720149391, 'num_leaves': 130, 'bagging_fraction': 0.8500352058428532, 'min_sum_hessian_in_leaf': 5.274166312626578, 'reg_alpha': 0.6631133209839596, 'reg_lambda': 9.629931290178343} scored 0.8099736467343647 in 0:00:27.635936\n",
      "[11:43:11] Training until validation scores don't improve for 100 rounds\n",
      "[11:43:40] \u001b[1mTrial 128\u001b[0m with hyperparameters {'feature_fraction': 0.6330344784678356, 'num_leaves': 148, 'bagging_fraction': 0.9260730597770056, 'min_sum_hessian_in_leaf': 5.40213077239259, 'reg_alpha': 0.7251213196797192, 'reg_lambda': 7.054324962663211} scored 0.8093659945103255 in 0:00:30.576989\n",
      "[11:43:42] Training until validation scores don't improve for 100 rounds\n",
      "[11:44:05] \u001b[1mTrial 129\u001b[0m with hyperparameters {'feature_fraction': 0.6171044261721456, 'num_leaves': 133, 'bagging_fraction': 0.9617026708427945, 'min_sum_hessian_in_leaf': 4.649160021995468, 'reg_alpha': 1.7620346677185925, 'reg_lambda': 2.3246804676879864} scored 0.8092988189419406 in 0:00:25.012389\n",
      "[11:44:07] Training until validation scores don't improve for 100 rounds\n",
      "[11:44:32] \u001b[1mTrial 130\u001b[0m with hyperparameters {'feature_fraction': 0.6629177088906784, 'num_leaves': 123, 'bagging_fraction': 0.8482654463303387, 'min_sum_hessian_in_leaf': 3.57357910204024, 'reg_alpha': 0.5957502092228623, 'reg_lambda': 9.815308261664711} scored 0.8098639422281122 in 0:00:26.761195\n",
      "[11:44:34] Training until validation scores don't improve for 100 rounds\n",
      "[11:44:58] \u001b[1mTrial 131\u001b[0m with hyperparameters {'feature_fraction': 0.644967251033697, 'num_leaves': 110, 'bagging_fraction': 0.9795008521544216, 'min_sum_hessian_in_leaf': 6.766044379460043, 'reg_alpha': 4.092495174016236, 'reg_lambda': 3.2759652257539704} scored 0.8098752384927753 in 0:00:26.345636\n",
      "[11:45:00] Training until validation scores don't improve for 100 rounds\n",
      "[11:45:21] \u001b[1mTrial 132\u001b[0m with hyperparameters {'feature_fraction': 0.6078918316020359, 'num_leaves': 130, 'bagging_fraction': 0.8977553116927823, 'min_sum_hessian_in_leaf': 2.848845250328769, 'reg_alpha': 0.10605812673423688, 'reg_lambda': 4.781183346021316} scored 0.8096126649337322 in 0:00:23.242648\n",
      "[11:45:23] Training until validation scores don't improve for 100 rounds\n",
      "[11:45:49] \u001b[1mTrial 133\u001b[0m with hyperparameters {'feature_fraction': 0.5872482810006001, 'num_leaves': 136, 'bagging_fraction': 0.9097651823745552, 'min_sum_hessian_in_leaf': 8.198483942018267, 'reg_alpha': 1.0018516863925353, 'reg_lambda': 1.666554712127259} scored 0.8093190731548167 in 0:00:27.288988\n",
      "[11:45:49] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:45:49] The set of hyperparameters \u001b[1m{'feature_fraction': 0.6511351777350247, 'num_leaves': 121, 'bagging_fraction': 0.9820013480881271, 'min_sum_hessian_in_leaf': 4.978628883167738, 'reg_alpha': 5.849967942534989e-07, 'reg_lambda': 5.186108599209899}\u001b[0m\n",
      " achieve 0.8106 auc\n",
      "[11:45:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:49] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:45:51] Training until validation scores don't improve for 100 rounds\n",
      "[11:46:20] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:46:22] Training until validation scores don't improve for 100 rounds\n",
      "[11:46:47] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:46:49] Training until validation scores don't improve for 100 rounds\n",
      "[11:47:09] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:47:11] Training until validation scores don't improve for 100 rounds\n",
      "[11:47:42] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:47:44] Training until validation scores don't improve for 100 rounds\n",
      "[11:48:08] ===== Start working with \u001b[1mfold 5\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:48:10] Training until validation scores don't improve for 100 rounds\n",
      "[11:48:34] ===== Start working with \u001b[1mfold 6\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
      "[11:48:36] Training until validation scores don't improve for 100 rounds\n",
      "[11:49:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8126746689775135\u001b[0m\n",
      "[11:49:09] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:49:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[11:49:09] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:49:10] 0:\ttest: 0.7430867\tbest: 0.7430867 (0)\ttotal: 147ms\tremaining: 7m 20s\n",
      "[11:50:51] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:50:51] bestTest = 0.8056796503\n",
      "[11:50:51] bestIteration = 1283\n",
      "[11:50:51] Shrink model to first 1284 iterations.\n",
      "[11:50:51] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:50:52] 0:\ttest: 0.7537147\tbest: 0.7537147 (0)\ttotal: 81.8ms\tremaining: 4m 5s\n",
      "[11:52:15] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:52:15] bestTest = 0.8131156826\n",
      "[11:52:15] bestIteration = 1037\n",
      "[11:52:15] Shrink model to first 1038 iterations.\n",
      "[11:52:16] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:52:18] 0:\ttest: 0.7408621\tbest: 0.7408621 (0)\ttotal: 88.7ms\tremaining: 4m 25s\n",
      "[11:53:20] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:53:20] bestTest = 0.8108351135\n",
      "[11:53:20] bestIteration = 750\n",
      "[11:53:20] Shrink model to first 751 iterations.\n",
      "[11:53:20] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:53:21] 0:\ttest: 0.7466051\tbest: 0.7466051 (0)\ttotal: 79.5ms\tremaining: 3m 58s\n",
      "[11:54:27] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:54:27] bestTest = 0.8081029316\n",
      "[11:54:27] bestIteration = 793\n",
      "[11:54:27] Shrink model to first 794 iterations.\n",
      "[11:54:27] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:54:28] 0:\ttest: 0.7429732\tbest: 0.7429732 (0)\ttotal: 83.2ms\tremaining: 4m 9s\n",
      "[11:55:57] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:55:57] bestTest = 0.8080190571\n",
      "[11:55:57] bestIteration = 1119\n",
      "[11:55:57] Shrink model to first 1120 iterations.\n",
      "[11:55:57] ===== Start working with \u001b[1mfold 5\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:55:58] 0:\ttest: 0.7587628\tbest: 0.7587628 (0)\ttotal: 85.8ms\tremaining: 4m 17s\n",
      "[11:57:52] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:57:52] bestTest = 0.8087996153\n",
      "[11:57:52] bestIteration = 1462\n",
      "[11:57:52] Shrink model to first 1463 iterations.\n",
      "[11:57:52] ===== Start working with \u001b[1mfold 6\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
      "[11:57:53] 0:\ttest: 0.7532356\tbest: 0.7532356 (0)\ttotal: 92.1ms\tremaining: 4m 36s\n",
      "[11:59:04] Stopped by overfitting detector  (100 iterations wait)\n",
      "[11:59:04] bestTest = 0.801540462\n",
      "[11:59:04] bestIteration = 859\n",
      "[11:59:04] Shrink model to first 860 iterations.\n",
      "[11:59:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.8079804026203743\u001b[0m\n",
      "[11:59:04] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[11:59:04] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 3600.00 secs\n",
      "[11:59:06] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 112ms\tremaining: 5m 34s\n",
      "[12:00:30] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:00:30] bestTest = 0.8047458481\n",
      "[12:00:30] bestIteration = 1214\n",
      "[12:00:30] Shrink model to first 1215 iterations.\n",
      "[12:00:30] \u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0024430162614261413, 'min_data_in_leaf': 4} scored 0.8047458455170386 in 0:01:26.367903\n",
      "[12:00:32] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 64.4ms\tremaining: 3m 13s\n",
      "[12:02:58] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:02:58] bestTest = 0.8047171785\n",
      "[12:02:58] bestIteration = 2511\n",
      "[12:02:58] Shrink model to first 2512 iterations.\n",
      "[12:02:58] \u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.002570603566117598, 'min_data_in_leaf': 15} scored 0.8047171811162669 in 0:02:27.290837\n",
      "[12:02:59] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 60.6ms\tremaining: 3m 1s\n",
      "[12:04:41] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:04:41] bestTest = 0.8040323903\n",
      "[12:04:41] bestIteration = 1718\n",
      "[12:04:41] Shrink model to first 1719 iterations.\n",
      "[12:04:41] \u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.8040323877033473 in 0:01:43.538265\n",
      "[12:04:43] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 64.1ms\tremaining: 3m 12s\n",
      "[12:06:46] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:06:46] bestTest = 0.8047934929\n",
      "[12:06:46] bestIteration = 2113\n",
      "[12:06:46] Shrink model to first 2114 iterations.\n",
      "[12:06:46] \u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 7.71800699380605e-05, 'min_data_in_leaf': 6} scored 0.8047934903295706 in 0:02:05.061209\n",
      "[12:06:48] 0:\ttest: 0.7470724\tbest: 0.7470724 (0)\ttotal: 82.5ms\tremaining: 4m 7s\n",
      "[12:07:30] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:07:30] bestTest = 0.8029334642\n",
      "[12:07:30] bestIteration = 409\n",
      "[12:07:30] Shrink model to first 410 iterations.\n",
      "[12:07:30] \u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 1.9826980964985924e-05, 'min_data_in_leaf': 10} scored 0.8029334668201112 in 0:00:44.083611\n",
      "[12:07:32] 0:\ttest: 0.7470724\tbest: 0.7470724 (0)\ttotal: 82.9ms\tremaining: 4m 8s\n",
      "[12:08:26] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:08:26] bestTest = 0.8040639382\n",
      "[12:08:26] bestIteration = 552\n",
      "[12:08:26] Shrink model to first 553 iterations.\n",
      "[12:08:26] \u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.804063945932212 in 0:00:55.644653\n",
      "[12:08:28] 0:\ttest: 0.7470559\tbest: 0.7470559 (0)\ttotal: 84.3ms\tremaining: 4m 12s\n",
      "[12:09:43] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:09:43] bestTest = 0.8062533413\n",
      "[12:09:43] bestIteration = 809\n",
      "[12:09:43] Shrink model to first 810 iterations.\n",
      "[12:09:44] \u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 3.4671276804481113, 'min_data_in_leaf': 20} scored 0.8062533335866121 in 0:01:17.413745\n",
      "[12:09:45] 0:\ttest: 0.7473302\tbest: 0.7473302 (0)\ttotal: 100ms\tremaining: 5m 1s\n",
      "[12:10:26] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:10:26] bestTest = 0.8027673947\n",
      "[12:10:26] bestIteration = 333\n",
      "[12:10:26] Shrink model to first 334 iterations.\n",
      "[12:10:26] \u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.014391207615728067, 'min_data_in_leaf': 9} scored 0.8027674024279713 in 0:00:42.494041\n",
      "[12:10:27] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 61.3ms\tremaining: 3m 3s\n",
      "[12:13:15] bestTest = 0.8050948748\n",
      "[12:13:15] bestIteration = 2950\n",
      "[12:13:15] Shrink model to first 2951 iterations.\n",
      "[12:13:15] \u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 1.527156759251193, 'min_data_in_leaf': 6} scored 0.8050948773579117 in 0:02:49.163673\n",
      "[12:13:17] 0:\ttest: 0.7470724\tbest: 0.7470724 (0)\ttotal: 82.7ms\tremaining: 4m 7s\n",
      "[12:14:12] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:14:12] bestTest = 0.803798848\n",
      "[12:14:12] bestIteration = 562\n",
      "[12:14:12] Shrink model to first 563 iterations.\n",
      "[12:14:12] \u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Min', 'l2_leaf_reg': 0.0008325158565947976, 'min_data_in_leaf': 4} scored 0.8037988480249127 in 0:00:56.694924\n",
      "[12:14:13] 0:\ttest: 0.7430716\tbest: 0.7430716 (0)\ttotal: 76.1ms\tremaining: 3m 48s\n",
      "[12:15:28] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:15:28] bestTest = 0.8051441835\n",
      "[12:15:28] bestIteration = 898\n",
      "[12:15:28] Shrink model to first 899 iterations.\n",
      "[12:15:29] \u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 5.31904907294463, 'min_data_in_leaf': 20} scored 0.8051441835378221 in 0:01:16.602106\n",
      "[12:15:30] 0:\ttest: 0.7431085\tbest: 0.7431085 (0)\ttotal: 77.1ms\tremaining: 3m 51s\n",
      "[12:17:16] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:17:16] bestTest = 0.8054580347\n",
      "[12:17:16] bestIteration = 1319\n",
      "[12:17:16] Shrink model to first 1320 iterations.\n",
      "[12:17:16] \u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 7.654538200209698, 'min_data_in_leaf': 20} scored 0.8054580346971643 in 0:01:47.235400\n",
      "[12:17:17] 0:\ttest: 0.7430811\tbest: 0.7430811 (0)\ttotal: 72.9ms\tremaining: 3m 38s\n",
      "[12:19:06] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:19:06] bestTest = 0.8056046794\n",
      "[12:19:06] bestIteration = 1384\n",
      "[12:19:06] Shrink model to first 1385 iterations.\n",
      "[12:19:06] \u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.2106831293560533, 'min_data_in_leaf': 20} scored 0.8056046768520045 in 0:01:50.291045\n",
      "[12:19:08] 0:\ttest: 0.7473285\tbest: 0.7473285 (0)\ttotal: 99.9ms\tremaining: 4m 59s\n",
      "[12:20:19] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:20:19] bestTest = 0.8047553151\n",
      "[12:20:19] bestIteration = 667\n",
      "[12:20:19] Shrink model to first 668 iterations.\n",
      "[12:20:19] \u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16505863700695908, 'min_data_in_leaf': 16} scored 0.8047553202202684 in 0:01:12.734388\n",
      "[12:20:20] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 65.7ms\tremaining: 3m 16s\n",
      "[12:22:58] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:22:58] bestTest = 0.8059058081\n",
      "[12:22:58] bestIteration = 2355\n",
      "[12:22:58] Shrink model to first 2356 iterations.\n",
      "[12:22:58] \u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.16506280795912764, 'min_data_in_leaf': 16} scored 0.8059058003352871 in 0:02:38.957838\n",
      "[12:22:59] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 68.5ms\tremaining: 3m 25s\n",
      "[12:25:11] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:25:11] bestTest = 0.8053450617\n",
      "[12:25:11] bestIteration = 1956\n",
      "[12:25:11] Shrink model to first 1957 iterations.\n",
      "[12:25:11] \u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.10130492013778519, 'min_data_in_leaf': 16} scored 0.8053450668829817 in 0:02:13.069687\n",
      "[12:25:12] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 100ms\tremaining: 5m\n",
      "[12:26:47] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:26:47] bestTest = 0.8047539818\n",
      "[12:26:47] bestIteration = 1384\n",
      "[12:26:47] Shrink model to first 1385 iterations.\n",
      "[12:26:48] \u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.024777290093244e-07, 'min_data_in_leaf': 13} scored 0.804753976657225 in 0:01:36.748550\n",
      "[12:26:49] 0:\ttest: 0.7470724\tbest: 0.7470724 (0)\ttotal: 86.3ms\tremaining: 4m 18s\n",
      "[12:28:31] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:28:31] bestTest = 0.8058270546\n",
      "[12:28:31] bestIteration = 1127\n",
      "[12:28:31] Shrink model to first 1128 iterations.\n",
      "[12:28:31] \u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.7003706012932384, 'min_data_in_leaf': 18} scored 0.80582704945453 in 0:01:43.064101\n",
      "[12:28:32] 0:\ttest: 0.7430867\tbest: 0.7430867 (0)\ttotal: 81.8ms\tremaining: 4m 5s\n",
      "[12:30:44] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:30:44] bestTest = 0.8057642586\n",
      "[12:30:44] bestIteration = 1714\n",
      "[12:30:44] Shrink model to first 1715 iterations.\n",
      "[12:30:44] \u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.028519940109301624, 'min_data_in_leaf': 13} scored 0.8057642611362359 in 0:02:13.191239\n",
      "[12:30:45] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 67.4ms\tremaining: 3m 22s\n",
      "[12:31:50] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:31:50] bestTest = 0.8033530125\n",
      "[12:31:50] bestIteration = 890\n",
      "[12:31:50] Shrink model to first 891 iterations.\n",
      "[12:31:50] \u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.02284282049076786, 'min_data_in_leaf': 18} scored 0.8033530072992267 in 0:01:05.752539\n",
      "[12:31:51] 0:\ttest: 0.7473150\tbest: 0.7473150 (0)\ttotal: 101ms\tremaining: 5m 1s\n",
      "[12:33:26] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:33:26] bestTest = 0.8055248201\n",
      "[12:33:26] bestIteration = 923\n",
      "[12:33:26] Shrink model to first 924 iterations.\n",
      "[12:33:26] \u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0848549659561568, 'min_data_in_leaf': 13} scored 0.8055248201155119 in 0:01:36.547218\n",
      "[12:33:28] 0:\ttest: 0.7470724\tbest: 0.7470724 (0)\ttotal: 88.6ms\tremaining: 4m 25s\n",
      "[12:34:32] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:34:32] bestTest = 0.8052771549\n",
      "[12:34:32] bestIteration = 666\n",
      "[12:34:32] Shrink model to first 667 iterations.\n",
      "[12:34:32] \u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.7839240693040945, 'min_data_in_leaf': 17} scored 0.8052771523549228 in 0:01:05.589699\n",
      "[12:34:33] 0:\ttest: 0.7469968\tbest: 0.7469968 (0)\ttotal: 84.2ms\tremaining: 4m 12s\n",
      "[12:35:58] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:35:58] bestTest = 0.8053192395\n",
      "[12:35:58] bestIteration = 915\n",
      "[12:35:58] Shrink model to first 916 iterations.\n",
      "[12:35:58] \u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 6.996694579428127, 'min_data_in_leaf': 18} scored 0.8053192368834763 in 0:01:26.168448\n",
      "[12:35:59] 0:\ttest: 0.7470724\tbest: 0.7470724 (0)\ttotal: 83.8ms\tremaining: 4m 11s\n",
      "[12:37:23] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:37:23] bestTest = 0.8056774127\n",
      "[12:37:23] bestIteration = 912\n",
      "[12:37:23] Shrink model to first 913 iterations.\n",
      "[12:37:23] \u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 6, 'nan_mode': 'Max', 'l2_leaf_reg': 0.3793075311750769, 'min_data_in_leaf': 18} scored 0.8056774049530431 in 0:01:24.708251\n",
      "[12:37:24] 0:\ttest: 0.7473301\tbest: 0.7473301 (0)\ttotal: 100ms\tremaining: 5m\n",
      "[12:38:17] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:38:17] bestTest = 0.8042041286\n",
      "[12:38:17] bestIteration = 469\n",
      "[12:38:17] Shrink model to first 470 iterations.\n",
      "[12:38:17] \u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 7, 'nan_mode': 'Max', 'l2_leaf_reg': 0.051210954053441574, 'min_data_in_leaf': 14} scored 0.8042041338168948 in 0:00:54.454168\n",
      "[12:38:19] 0:\ttest: 0.7430775\tbest: 0.7430775 (0)\ttotal: 73.8ms\tremaining: 3m 41s\n",
      "[12:39:54] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:39:54] bestTest = 0.8055688528\n",
      "[12:39:54] bestIteration = 1190\n",
      "[12:39:54] Shrink model to first 1191 iterations.\n",
      "[12:39:54] \u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 1.0816225891633813, 'min_data_in_leaf': 19} scored 0.8055688579780278 in 0:01:36.858055\n",
      "[12:39:55] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 67.1ms\tremaining: 3m 21s\n",
      "[12:41:30] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:41:30] bestTest = 0.80496473\n",
      "[12:41:30] bestIteration = 1373\n",
      "[12:41:30] Shrink model to first 1374 iterations.\n",
      "[12:41:30] \u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Min', 'l2_leaf_reg': 0.00011482225105495548, 'min_data_in_leaf': 11} scored 0.8049647377745272 in 0:01:36.166521\n",
      "[12:41:32] 0:\ttest: 0.7430691\tbest: 0.7430691 (0)\ttotal: 75ms\tremaining: 3m 44s\n",
      "[12:43:12] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:43:12] bestTest = 0.8059019841\n",
      "[12:43:12] bestIteration = 1261\n",
      "[12:43:12] Shrink model to first 1262 iterations.\n",
      "[12:43:13] \u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 2.522620882466841, 'min_data_in_leaf': 16} scored 0.8059019815157145 in 0:01:42.367572\n",
      "[12:43:14] 0:\ttest: 0.7430867\tbest: 0.7430867 (0)\ttotal: 72.2ms\tremaining: 3m 36s\n",
      "[12:44:48] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:44:48] bestTest = 0.8051869709\n",
      "[12:44:48] bestIteration = 1180\n",
      "[12:44:48] Shrink model to first 1181 iterations.\n",
      "[12:44:48] \u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 5, 'nan_mode': 'Max', 'l2_leaf_reg': 0.0067863708630453105, 'min_data_in_leaf': 15} scored 0.8051869631018728 in 0:01:35.172016\n",
      "[12:44:49] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 69.7ms\tremaining: 3m 29s\n",
      "[12:47:00] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:47:00] bestTest = 0.8059685783\n",
      "[12:47:00] bestIteration = 1914\n",
      "[12:47:00] Shrink model to first 1915 iterations.\n",
      "[12:47:00] \u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 2.8540531776263873, 'min_data_in_leaf': 11} scored 0.8059685783184809 in 0:02:12.397036\n",
      "[12:47:02] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 74.5ms\tremaining: 3m 43s\n",
      "[12:48:40] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:48:40] bestTest = 0.8050993189\n",
      "[12:48:40] bestIteration = 1437\n",
      "[12:48:40] Shrink model to first 1438 iterations.\n",
      "[12:48:40] \u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 1.2891494276763507e-08, 'min_data_in_leaf': 9} scored 0.8050993214510547 in 0:01:39.855009\n",
      "[12:48:42] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 68.9ms\tremaining: 3m 26s\n",
      "[12:51:10] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:51:10] bestTest = 0.8063042417\n",
      "[12:51:10] bestIteration = 2185\n",
      "[12:51:10] Shrink model to first 2186 iterations.\n",
      "[12:51:10] \u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 4.261096246188244, 'min_data_in_leaf': 11} scored 0.8063042391232991 in 0:02:30.006265\n",
      "[12:51:11] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 69.3ms\tremaining: 3m 27s\n",
      "[12:52:36] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:52:36] bestTest = 0.8042824945\n",
      "[12:52:36] bestIteration = 1192\n",
      "[12:52:36] Shrink model to first 1193 iterations.\n",
      "[12:52:37] \u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 3.0897363380308276, 'min_data_in_leaf': 11} scored 0.8042824867962892 in 0:01:26.528321\n",
      "[12:52:38] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 62.7ms\tremaining: 3m 8s\n",
      "[12:54:58] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:54:58] bestTest = 0.8042653383\n",
      "[12:54:58] bestIteration = 2351\n",
      "[12:54:58] Shrink model to first 2352 iterations.\n",
      "[12:54:58] \u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Max', 'l2_leaf_reg': 9.820773745848513, 'min_data_in_leaf': 7} scored 0.8042653331135126 in 0:02:21.619156\n",
      "[12:55:00] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 62.2ms\tremaining: 3m 6s\n",
      "[12:56:39] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:56:39] bestTest = 0.8041282793\n",
      "[12:56:39] bestIteration = 1675\n",
      "[12:56:39] Shrink model to first 1676 iterations.\n",
      "[12:56:40] \u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 0.25808238788187193, 'min_data_in_leaf': 8} scored 0.8041282715966803 in 0:01:41.432493\n",
      "[12:56:41] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 67.8ms\tremaining: 3m 23s\n",
      "[12:58:34] Stopped by overfitting detector  (100 iterations wait)\n",
      "[12:58:34] bestTest = 0.805085227\n",
      "[12:58:34] bestIteration = 1650\n",
      "[12:58:34] Shrink model to first 1651 iterations.\n",
      "[12:58:34] \u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 0.09863773508283777, 'min_data_in_leaf': 12} scored 0.8050852295417515 in 0:01:54.094606\n",
      "[12:58:35] 0:\ttest: 0.7279309\tbest: 0.7279309 (0)\ttotal: 59.9ms\tremaining: 2m 59s\n",
      "[13:00:15] Stopped by overfitting detector  (100 iterations wait)\n",
      "[13:00:15] bestTest = 0.8041141048\n",
      "[13:00:15] bestIteration = 1683\n",
      "[13:00:15] Shrink model to first 1684 iterations.\n",
      "[13:00:15] \u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 3, 'nan_mode': 'Min', 'l2_leaf_reg': 8.31819570043442e-06, 'min_data_in_leaf': 14} scored 0.8041141047578999 in 0:01:41.442871\n",
      "[13:00:15] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[13:00:15] The set of hyperparameters \u001b[1m{'max_depth': 4, 'nan_mode': 'Max', 'l2_leaf_reg': 4.261096246188244, 'min_data_in_leaf': 11}\u001b[0m\n",
      " achieve 0.8063 auc\n",
      "[13:00:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[13:00:15] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:00:16] 0:\ttest: 0.7287609\tbest: 0.7287609 (0)\ttotal: 67.1ms\tremaining: 3m 21s\n",
      "[13:03:16] Stopped by overfitting detector  (100 iterations wait)\n",
      "[13:03:16] bestTest = 0.805623789\n",
      "[13:03:16] bestIteration = 2642\n",
      "[13:03:16] Shrink model to first 2643 iterations.\n",
      "[13:03:16] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:03:17] 0:\ttest: 0.7337071\tbest: 0.7337071 (0)\ttotal: 75.5ms\tremaining: 3m 46s\n",
      "[13:05:13] Stopped by overfitting detector  (100 iterations wait)\n",
      "[13:05:13] bestTest = 0.8130837161\n",
      "[13:05:13] bestIteration = 1665\n",
      "[13:05:13] Shrink model to first 1666 iterations.\n",
      "[13:05:13] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:05:14] 0:\ttest: 0.7214900\tbest: 0.7214900 (0)\ttotal: 78.6ms\tremaining: 3m 55s\n",
      "[13:07:35] Stopped by overfitting detector  (100 iterations wait)\n",
      "[13:07:35] bestTest = 0.8109155723\n",
      "[13:07:35] bestIteration = 2031\n",
      "[13:07:35] Shrink model to first 2032 iterations.\n",
      "[13:07:35] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:07:36] 0:\ttest: 0.7237199\tbest: 0.7237199 (0)\ttotal: 72.7ms\tremaining: 3m 38s\n",
      "[13:10:50] Stopped by overfitting detector  (100 iterations wait)\n",
      "[13:10:50] bestTest = 0.808604339\n",
      "[13:10:50] bestIteration = 2870\n",
      "[13:10:50] Shrink model to first 2871 iterations.\n",
      "[13:10:50] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:10:51] 0:\ttest: 0.7242467\tbest: 0.7242467 (0)\ttotal: 77.1ms\tremaining: 3m 51s\n",
      "[13:14:07] bestTest = 0.8083177156\n",
      "[13:14:07] bestIteration = 2998\n",
      "[13:14:07] Shrink model to first 2999 iterations.\n",
      "[13:14:07] ===== Start working with \u001b[1mfold 5\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:14:08] 0:\ttest: 0.7575012\tbest: 0.7575012 (0)\ttotal: 74.6ms\tremaining: 3m 43s\n",
      "[13:17:24] bestTest = 0.8093494351\n",
      "[13:17:24] bestIteration = 2998\n",
      "[13:17:24] Shrink model to first 2999 iterations.\n",
      "[13:17:24] ===== Start working with \u001b[1mfold 6\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
      "[13:17:25] 0:\ttest: 0.7527291\tbest: 0.7527291 (0)\ttotal: 80.7ms\tremaining: 4m 1s\n",
      "[13:20:20] Stopped by overfitting detector  (100 iterations wait)\n",
      "[13:20:20] bestTest = 0.8022107565\n",
      "[13:20:20] bestIteration = 2570\n",
      "[13:20:20] Shrink model to first 2571 iterations.\n",
      "[13:20:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.8082572612696439\u001b[0m\n",
      "[13:20:20] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[13:20:20] Time left 26452.12 secs\n",
      "\n",
      "[13:20:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[13:20:20] Blending: optimization starts with equal weights and score \u001b[1m0.8105141267387155\u001b[0m\n",
      "[13:20:26] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8132747220143421\u001b[0m, weights = \u001b[1m[0.         0.12311481 0.7100237  0.08533342 0.08152805]\u001b[0m\n",
      "[13:20:32] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.813300867532984\u001b[0m, weights = \u001b[1m[0.         0.17986456 0.6588725  0.10440635 0.05685665]\u001b[0m\n",
      "[13:20:38] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8133022873019988\u001b[0m, weights = \u001b[1m[0.         0.17232272 0.65459913 0.11425159 0.05882651]\u001b[0m\n",
      "[13:20:44] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8133024031068034\u001b[0m, weights = \u001b[1m[0.         0.1708656  0.65693897 0.11386634 0.05832908]\u001b[0m\n",
      "[13:20:49] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8133024430267657\u001b[0m, weights = \u001b[1m[0.         0.17114136 0.65638524 0.11405011 0.05842322]\u001b[0m\n",
      "[13:20:49] \u001b[1mAutoml preset training completed in 9577.11 seconds\u001b[0m\n",
      "\n",
      "[13:20:49] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.17114 * (7 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.65639 * (7 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.11405 * (7 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.05842 * (7 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "CPU times: user 9h 53min 36s, sys: 8min 12s, total: 10h 1min 49s\n",
      "Wall time: 2h 39min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof_pred = automl.fit_predict(train_df, roles={'target': TARGET_NAME}, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d16bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T13:20:50.044348Z",
     "iopub.status.busy": "2024-11-04T13:20:50.043282Z",
     "iopub.status.idle": "2024-11-04T13:20:50.049769Z",
     "shell.execute_reply": "2024-11-04T13:20:50.048633Z"
    },
    "papermill": {
     "duration": 0.114904,
     "end_time": "2024-11-04T13:20:50.052252",
     "exception": false,
     "start_time": "2024-11-04T13:20:49.937348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction for new objects (level 0) = \n",
      "\t 0.17114 * (7 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.65639 * (7 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.11405 * (7 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.05842 * (7 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n"
     ]
    }
   ],
   "source": [
    "print(automl.create_model_str_desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2096a60a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T13:20:50.262325Z",
     "iopub.status.busy": "2024-11-04T13:20:50.261445Z",
     "iopub.status.idle": "2024-11-04T13:20:50.415283Z",
     "shell.execute_reply": "2024-11-04T13:20:50.413901Z"
    },
    "papermill": {
     "duration": 0.260242,
     "end_time": "2024-11-04T13:20:50.417649",
     "exception": false,
     "start_time": "2024-11-04T13:20:50.157407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN out-of-fold score: 0.8133024430267657\n"
     ]
    }
   ],
   "source": [
    "print(f'TRAIN out-of-fold score: {roc_auc_score(train_df[TARGET_NAME].values, oof_pred.data.flatten())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8edb68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T13:20:50.631066Z",
     "iopub.status.busy": "2024-11-04T13:20:50.630206Z",
     "iopub.status.idle": "2024-11-04T13:21:08.630372Z",
     "shell.execute_reply": "2024-11-04T13:21:08.629086Z"
    },
    "papermill": {
     "duration": 18.11018,
     "end_time": "2024-11-04T13:21:08.632553",
     "exception": false,
     "start_time": "2024-11-04T13:20:50.522373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 84.9 ms, total: 1min 4s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = automl.predict(test_df).data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed074ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T13:21:08.844984Z",
     "iopub.status.busy": "2024-11-04T13:21:08.844015Z",
     "iopub.status.idle": "2024-11-04T13:21:09.583660Z",
     "shell.execute_reply": "2024-11-04T13:21:09.582506Z"
    },
    "papermill": {
     "duration": 0.848249,
     "end_time": "2024-11-04T13:21:09.586288",
     "exception": false,
     "start_time": "2024-11-04T13:21:08.738039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "subm = pd.read_csv('/data/Кейс-3. Отток юридических лиц из расчетно-кассового обслуживания/baseline_submission_case3.csv')\n",
    "subm['target'] = pred\n",
    "subm['id'] = ids\n",
    "subm['id'] = subm['id'].astype(int)\n",
    "\n",
    "with open('submission_laml.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(subm.columns)\n",
    "    writer.writerows(subm.values)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5993029,
     "sourceId": 9782155,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9829.033046,
   "end_time": "2024-11-04T13:21:13.049763",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-04T10:37:24.016717",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
